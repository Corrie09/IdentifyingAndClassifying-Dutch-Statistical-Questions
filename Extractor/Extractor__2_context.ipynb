{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a57c7c0-b35d-484e-b8e6-e5bee3e20c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jefva\\AppData\\Local\\Temp\\ipykernel_17480\\2918946827.py:161: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: ''.join(c for c in str(x) if c.isprintable()) if isinstance(x, str) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extraction complete! File saved at: C:\\Users\\jefva\\Documents\\Master\\Thesis_s2\\Code\\Data\\Grote_data_cleaned.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Get paths\n",
    "script_dir = os.getcwd()\n",
    "project_root = os.path.dirname(script_dir)\n",
    "folder_path = os.path.join(project_root, \"Data\", \"ScrapeddocumentsCorneel(22-25)\")\n",
    "excel_path = os.path.join(project_root, \"Data\")\n",
    "\n",
    "# Statistical patterns\n",
    "dutch_statistical_patterns = [\n",
    "    r\"\\b(hoeveel|aantal|percentage van|percentage|cijfer over|data over|statistieken van)\\b\",\n",
    "    r\"\\b(trend in|evolutie van|groei van|toename van|afname van|ontwikkeling van)\\b\",\n",
    "    r\"\\b(?:verschaffen|geven|tonen|lijst|overzicht van)?\\s*(de|een)?\\s*(gegevens|statistieken|cijfers)\\b\"\n",
    "]\n",
    "\n",
    "def is_dutch_statistical(question):\n",
    "    return any(re.search(pattern, question, re.IGNORECASE) for pattern in dutch_statistical_patterns)\n",
    "\n",
    "# Metadata removal\n",
    "def remove_metadata(text):\n",
    "    metadata_patterns = [\n",
    "        r\"(?i)^title:.*\", r\"(?i)^thema:.*\", r\"(?i)^pdf link:.*\", r\"(?i)^thema link:.*\",\n",
    "        r\"(?i)^SCHRIFTELIJKE VRAAG.*\", r\"(?i)^nr\\.\\s*\\d+\\s*$\", r\"(?i)^van\\s+.*\",\n",
    "        r\"(?i)^datum:.*\", r\"(?i)^aan\\s+.*\", r\"(?i)^onderwerp:.*\",\n",
    "        r\"(?i)^programma’s.*\", r\"(?i)^vraag van.*\"\n",
    "    ]\n",
    "    lines = text.split(\"\\n\")\n",
    "\n",
    "    def is_fully_uppercase(line):\n",
    "        words = re.findall(r\"[A-Za-zÀ-ÿ]\", line)\n",
    "        return words and all(word.isupper() for word in words)\n",
    "\n",
    "    filtered_lines = [line for line in lines if not any(re.search(pattern, line) for pattern in metadata_patterns) and not is_fully_uppercase(line)]\n",
    "    return \"\\n\".join(filtered_lines).strip()\n",
    "\n",
    "# Smart sentence splitter\n",
    "def smart_sentence_split(text):\n",
    "    abbreviations = [\n",
    "        \"t.o.v.\", \"a.d.h.v.\", \"i.v.m.\", \"m.b.t.\", \"m.a.w.\", \"d.w.z.\",\n",
    "        \"z.o.z.\", \"o.a.\", \"e.d.\", \"e.o.\", \"n.a.v.\", \"v.w.b.\", \"c.q.\",\n",
    "        \"d.d.\", \"m.n.\", \"p.m.\", \"r.i.p.\", \"s.v.p.\", \"t.a.v.\", \"t.k.\",\n",
    "        \"t.z.t.\", \"z.g.a.n.\", \"z.s.m.\", \"z.n.\", \"z.d.\", \"z.m.\",\n",
    "    ]\n",
    "\n",
    "    special_prefixes = [\n",
    "        r\"\\b\\d+\\.\", r\"\\bnr\\.\", r\"\\b[ivxlcdm]+\\.\"\n",
    "    ]\n",
    "\n",
    "    abbr_map = {abbr: f\"__AFKORTING_{i}__\" for i, abbr in enumerate(abbreviations)}\n",
    "    for abbr, placeholder in abbr_map.items():\n",
    "        text = text.replace(abbr, placeholder)\n",
    "\n",
    "    prefix_map = {}\n",
    "    for i, regex in enumerate(special_prefixes):\n",
    "        matches = list(re.finditer(regex, text, flags=re.IGNORECASE))\n",
    "        for j, match in enumerate(matches):\n",
    "            key = f\"__PREFIX_{i}_{j}__\"\n",
    "            prefix_map[key] = match.group()\n",
    "            text = text.replace(match.group(), key, 1)\n",
    "\n",
    "    sentences = re.split(r'(?<=[.?!])\\s+', text)\n",
    "\n",
    "    restored = []\n",
    "    for sentence in sentences:\n",
    "        for abbr, placeholder in abbr_map.items():\n",
    "            sentence = sentence.replace(placeholder, abbr)\n",
    "        for key, original in prefix_map.items():\n",
    "            sentence = sentence.replace(key, original)\n",
    "        restored.append(sentence)\n",
    "\n",
    "    return restored\n",
    "\n",
    "# Main question extraction\n",
    "def extract_questions_with_custom_subgrouping(text):\n",
    "    text = remove_metadata(text)\n",
    "    sentences = smart_sentence_split(text)\n",
    "\n",
    "    extracted_data = []\n",
    "    prev_non_question_sentences = []\n",
    "    current_question_group = []\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        is_question = re.search(r\"\\?\", sentence)\n",
    "        is_subquestion = re.match(r\"^\\s*([a-z]\\)|[ivxlcdm]+\\.)?\\s*(Zo ja|Graag)\\b\", sentence, re.IGNORECASE)\n",
    "        is_numbered_list_item = re.match(r\"^\\s*\\d+\\.\", sentence)\n",
    "        is_lettered_list_item = re.match(r\"^\\s*[a-z]\\)\", sentence, re.IGNORECASE)\n",
    "        is_roman_item = re.match(r\"^\\s*[ivxlcdm]+\\.\", sentence, re.IGNORECASE)\n",
    "        is_nr_item = re.match(r\"^\\s*nr\\.\", sentence, re.IGNORECASE)\n",
    "\n",
    "        # Get previous sentence if it exists\n",
    "        previous_sentence = sentences[i - 1] if i > 0 else \"\"\n",
    "        previous_is_question = re.search(r\"\\?\", previous_sentence)\n",
    "\n",
    "        if is_question:\n",
    "            if current_question_group and is_subquestion:\n",
    "                current_question_group.append(sentence)\n",
    "            else:\n",
    "                if current_question_group:\n",
    "                    context = \" \".join(prev_non_question_sentences[-2:])\n",
    "                    full_question = \" \".join(current_question_group)\n",
    "                    extracted_data.append((context, full_question))\n",
    "                    current_question_group = []\n",
    "                current_question_group.append(sentence)\n",
    "\n",
    "        elif is_subquestion and not previous_is_question:\n",
    "            # Graag-line not following a question → treat as standalone question\n",
    "            if current_question_group:\n",
    "                context = \" \".join(prev_non_question_sentences[-2:])\n",
    "                full_question = \" \".join(current_question_group)\n",
    "                extracted_data.append((context, full_question))\n",
    "                current_question_group = []\n",
    "\n",
    "            current_question_group.append(sentence)\n",
    "\n",
    "        else:\n",
    "            if (\n",
    "                not is_numbered_list_item and\n",
    "                not is_lettered_list_item and\n",
    "                not is_roman_item and\n",
    "                not is_nr_item and\n",
    "                not re.search(r\"\\?\", sentence) and\n",
    "                not is_subquestion\n",
    "            ):\n",
    "                prev_non_question_sentences.append(sentence)\n",
    "                if len(prev_non_question_sentences) > 2:\n",
    "                    prev_non_question_sentences.pop(0)\n",
    "\n",
    "            if current_question_group:\n",
    "                context = \" \".join(prev_non_question_sentences[-2:])\n",
    "                full_question = \" \".join(current_question_group)\n",
    "                extracted_data.append((context, full_question))\n",
    "                current_question_group = []\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "\n",
    "# Process all files\n",
    "data = []\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            content = file.read()\n",
    "            theme_match = re.search(r\"thema:\\s*(.+)\", content, re.IGNORECASE)\n",
    "            theme = theme_match.group(1).strip() if theme_match else \"Unknown\"\n",
    "            questions_with_custom_subgrouping = extract_questions_with_custom_subgrouping(content)\n",
    "\n",
    "            for context, question in questions_with_custom_subgrouping:\n",
    "                data.append({\n",
    "                    \"context\": context,\n",
    "                    \"question\": question,\n",
    "                    \"statistical\": 1 if is_dutch_statistical(question) else 0,\n",
    "                    \"theme\": theme,\n",
    "                    \"file_name\": file_name\n",
    "                })\n",
    "\n",
    "# Export to Excel\n",
    "df = pd.DataFrame(data)\n",
    "df = df.applymap(lambda x: ''.join(c for c in str(x) if c.isprintable()) if isinstance(x, str) else x)\n",
    "output_excel_path = os.path.join(excel_path, \"Grote_data_cleaned.xlsx\")\n",
    "df.to_excel(output_excel_path, index=False, engine=\"openpyxl\")\n",
    "\n",
    "print(f\"✅ Extraction complete! File saved at: {output_excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecb61af-2e5a-4bc6-86d0-47cf12dcbe24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
