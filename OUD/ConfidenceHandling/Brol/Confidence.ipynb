{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\corne\\anaconda3\\envs\\thesis-env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import torch.nn.functional as F\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29564\\1437698013.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"context\"].fillna(\"\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All theme_ids: [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11), np.int64(12), np.int64(13), np.int64(14), np.int64(15), np.int64(16), np.int64(17), np.int64(18), np.int64(19), np.int64(20), np.int64(21), np.int64(22), np.int64(23), np.int64(24), np.int64(25), np.int64(26), np.int64(27), np.int64(28), np.int64(29), np.int64(30), np.int64(31), np.int64(32), np.int64(33), np.int64(34), np.int64(35), np.int64(36)]\n",
      "num_labels: 37\n"
     ]
    }
   ],
   "source": [
    "# ✅ 1. Load & Preprocess Data\n",
    "script_dir = os.getcwd() # Ga één map omhoog om 'baseline' te verwijderen en ga naar 'Data'\n",
    "project_root = os.path.dirname(script_dir)  # Dit verwijdert 'baseline' van het script_dir\n",
    "data_folder = os.path.join(project_root, \"Data\")\n",
    "\n",
    "# 1. Dataset inladen\n",
    "file_path = os.path.join(data_folder, \"Grote_data_cleaned.xlsx\")\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "if \"TXT_file_name\" in df.columns:\n",
    "    df = df.drop(columns=[\"TXT_file_name\"])\n",
    "\n",
    "# Handle missing values\n",
    "df = df.dropna(subset=[\"question\"])\n",
    "df[\"context\"].fillna(\"\", inplace=True)\n",
    "\n",
    "# Clean text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\n', ' ', text)  # Replace newlines with spaces\n",
    "    text = re.sub(r'\\b[a-z]\\)\\s+', ' ', text)  # Remove patterns like 'a)', 'b)', etc.\n",
    "    text = re.sub(r'\\b\\d+\\.\\b', '', text)  # Remove patterns like '1.', '2.', etc.\n",
    "    text = re.sub(r'\\b\\d+\\)\\b', '', text)  # Remove patterns like '1)', '2)', etc.\n",
    "    text = re.sub(r'\\b[i]+[.)]\\b', '', text, flags=re.IGNORECASE)  # Remove patterns like 'i.', 'ii.', 'i)', etc.\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces and trim\n",
    "    text = re.sub(r'\\b\\d+[.)]\\s*', '', text) # Remove numeric list markers like 1., 2. or 1) 2)\n",
    "    text = re.sub(r'\\b[ivxlcdm]+\\s*[.)]\\s*', '', text, flags=re.IGNORECASE)# Remove roman numerals like i. ii. iii. or i) ii) iii)\n",
    "    return text\n",
    "\n",
    "# df[\"clean_text\"] = (df[\"context\"] + \" \" + df[\"question\"]).apply(clean_text)\n",
    "df[\"clean_text\"] = (df[\"question\"]).apply(clean_text) \n",
    "\n",
    "# Group by 'clean_text' and count unique themes\n",
    "duplicates_with_diff_themes = df.groupby(\"clean_text\")[\"theme\"].nunique().reset_index()\n",
    "\n",
    "# Filter rows where the number of unique themes is greater than 1\n",
    "duplicates_with_diff_themes = duplicates_with_diff_themes[duplicates_with_diff_themes[\"theme\"] > 1]\n",
    "\n",
    "# Merge back with the original dataframe to get all rows with these 'clean_text'\n",
    "filtered_df = df[df[\"clean_text\"].isin(duplicates_with_diff_themes[\"clean_text\"])]\n",
    "# Exclude rows with these 'clean_text' from the original dataframe\n",
    "df = df[~df[\"clean_text\"].isin(duplicates_with_diff_themes[\"clean_text\"])]\n",
    "\n",
    "# ✅ Now: drop rare themes using original theme names\n",
    "theme_counts = df[\"theme\"].value_counts()\n",
    "valid_themes = theme_counts[theme_counts >= 2].index\n",
    "df = df[df[\"theme\"].isin(valid_themes)]\n",
    "\n",
    "# ✅ Recompute label encoding AFTER filtering\n",
    "unique_themes = list(df[\"theme\"].unique())\n",
    "theme_to_id = {theme: idx for idx, theme in enumerate(unique_themes)}\n",
    "id_to_theme = {idx: theme for theme, idx in theme_to_id.items()}\n",
    "df[\"theme_id\"] = df[\"theme\"].map(theme_to_id)\n",
    "\n",
    "print(\"All theme_ids:\", sorted(df[\"theme_id\"].unique()))\n",
    "print(\"num_labels:\", df[\"theme_id\"].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after oversampling: Counter({15: 4841, 4: 1521, 9: 1455, 26: 1066, 12: 972, 6: 776, 21: 742, 20: 635, 0: 602, 16: 573, 28: 560, 14: 539, 8: 449, 1: 398, 17: 343, 11: 314, 22: 281, 23: 261, 7: 233, 35: 233, 18: 233, 19: 233, 32: 233, 29: 233, 24: 233, 5: 233, 31: 233, 13: 233, 2: 233, 30: 233, 25: 233, 3: 233, 27: 233, 10: 233, 36: 233, 33: 233, 34: 233})\n"
     ]
    }
   ],
   "source": [
    "# ✅ 5. Split Data into Train & Test\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df[\"clean_text\"].tolist(), df[\"theme_id\"].tolist(), test_size=0.2, random_state=42, stratify=df[\"theme_id\"]\n",
    ")\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pandas as pd\n",
    "\n",
    "# Create a small DataFrame from train lists\n",
    "train_df = pd.DataFrame({\n",
    "    \"clean_text\": train_texts,\n",
    "    \"theme_id\": train_labels\n",
    "})\n",
    "\n",
    "# Compute class counts and use median as balancing target\n",
    "theme_counts = train_df[\"theme_id\"].value_counts()\n",
    "median_count = theme_counts.median()\n",
    "\n",
    "# Define strategy: only oversample underrepresented classes\n",
    "sampling_strategy = {\n",
    "    theme: int(median_count)\n",
    "    for theme in theme_counts.index\n",
    "    if theme_counts[theme] < median_count\n",
    "}\n",
    "\n",
    "# Apply RandomOverSampler\n",
    "ros = RandomOverSampler(sampling_strategy=sampling_strategy, random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(train_df[[\"clean_text\"]], train_df[\"theme_id\"])\n",
    "\n",
    "# Extract oversampled train lists\n",
    "train_texts_resampled = X_resampled[\"clean_text\"].tolist()\n",
    "train_labels_resampled = y_resampled.tolist()\n",
    "\n",
    "from collections import Counter\n",
    "print(\"Class distribution after oversampling:\", Counter(train_labels_resampled))\n",
    "\n",
    "\n",
    "# ✅ 7. Load BERT Tokenizer & Define Dataset Class\n",
    "model_name = \"GroNLP/bert-base-dutch-cased\"              # aanpassen naar welk model je wilt evaluaten \n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "class ThemeDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx], padding=\"max_length\", truncation=True, max_length=self.max_length, return_tensors=\"pt\"\n",
    "        )\n",
    "        encoding[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "\n",
    "train_dataset = ThemeDataset(train_texts_resampled, train_labels_resampled, tokenizer)\n",
    "test_dataset = ThemeDataset(test_texts, test_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD THE MODEL YOU WANT TO EVALUATE FROM KUL DRIVE!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 20755\n",
      "Test dataset size: 4583\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dataset size:\", len(train_dataset))\n",
    "print(\"Test dataset size:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/corne/OneDrive - KU Leuven/Thesis/Working Code/SAVED-Models/GroNLP/Run_2025-04-07_23-42\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "model_path = \"C:/Users/corne/OneDrive - KU Leuven/Thesis/Working Code/SAVED-Models/GroNLP/Run_2025-04-07_23-42\"        # ook naam tokenize in cel hierboven aanpassen !!!\n",
    "#model_path = r\"C:\\Users\\jefva\\Documents\\Master\\Thesis_s2\\Code\\BERT_Classifiers\\results\\checkpoint-13790\"\n",
    "\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(model_path).cuda()\n",
    "print(model.config._name_or_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=\"./results\", per_device_eval_batch_size=8)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 573/573 [01:18<00:00,  7.33it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HANDLE UNKNOWNS and save those predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved to low_confidence_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "# Step 2: Convert logits to softmax probabilities\n",
    "logits = torch.tensor(predictions.predictions)\n",
    "probs = F.softmax(logits, dim=1)\n",
    "\n",
    "# Step 3: Extract top confidence and predicted label\n",
    "confidences, pred_ids = torch.max(probs, dim=1)\n",
    "\n",
    "# Step 4: Create DataFrame for analysis\n",
    "df_conf = pd.DataFrame({\n",
    "    \"question\": test_texts,  # should match the input order of test_dataset\n",
    "    \"true_label_id\": predictions.label_ids,\n",
    "    \"predicted_label_id\": pred_ids.numpy(),\n",
    "    \"confidence\": confidences.numpy()\n",
    "})\n",
    "\n",
    "# Step 5: Add theme names (optional)\n",
    "df_conf[\"true_theme\"] = df_conf[\"true_label_id\"].map(id_to_theme)\n",
    "df_conf[\"predicted_theme\"] = df_conf[\"predicted_label_id\"].map(id_to_theme)\n",
    "\n",
    "# Step 6: Sort by confidence to see vague cases\n",
    "df_conf_sorted = df_conf.sort_values(\"confidence\")\n",
    "\n",
    "# Save or inspect\n",
    "df_conf_sorted.to_excel(\"bert_predictions_with_confidence.xlsx\", index=False)\n",
    "df_conf_sorted.head(10)  # Show least confident predictions\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic Threshold: 0.41512388348579404\n"
     ]
    }
   ],
   "source": [
    "# ✅ 13. Make Predictions (With Dynamic Confidence Threshold & Short Question Handling)\n",
    "probabilities = F.softmax(torch.tensor(predictions.predictions), dim=1)\n",
    "\n",
    "# ✅ Dynamically Adjust the Confidence Threshold (1st Percentile)\n",
    "confidence_values = torch.max(probabilities, dim=1)[0].tolist()\n",
    "dynamic_threshold = np.percentile(confidence_values, 1)  # ✅ Set threshold at the 5th percentile\n",
    "print(f\"Dynamic Threshold: {dynamic_threshold}\")  # ✅ Print the new threshold\n",
    "\n",
    "# ✅ Predict Themes with \"Unknown\" for Unclear Questions\n",
    "predicted_labels = []\n",
    "for i in range(len(probabilities)):\n",
    "    max_prob = torch.max(probabilities[i]).item()\n",
    "    pred_label = torch.argmax(probabilities[i]).item()\n",
    "    question_text = test_texts[i]\n",
    "\n",
    "    # ✅ If question is too short and lacks context, assign \"Unknown\"\n",
    "    if len(question_text.split()) < 4:\n",
    "        predicted_labels.append(\"Unknown\")\n",
    "    elif max_prob < dynamic_threshold:\n",
    "        predicted_labels.append(\"Unknown\")  # ✅ Filter out low-confidence predictions\n",
    "    else:\n",
    "        predicted_labels.append(id_to_theme[pred_label])  # ✅ Assign label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model Training Completed! Predictions saved.\n"
     ]
    }
   ],
   "source": [
    "# Create list of results\n",
    "results = [\n",
    "    \"Unknown\" if pred == \"Unknown\"\n",
    "    else \"Correct\" if id_to_theme[true_label] == pred\n",
    "    else \"Incorrect\"\n",
    "    for true_label, pred in zip(test_labels, predicted_labels)\n",
    "]\n",
    "\n",
    "# Create DataFrame with results column\n",
    "output_df = pd.DataFrame({\n",
    "    \"Text\": test_texts,\n",
    "    \"True_Theme\": [id_to_theme[label] for label in test_labels],\n",
    "    \"Predicted_Theme\": predicted_labels,\n",
    "    \"Result\": results\n",
    "})\n",
    "\n",
    "# Save to Excel\n",
    "output_df.to_excel(\"test.xlsx\", index=False)\n",
    "print(\"✅ Model Training Completed! Predictions saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
