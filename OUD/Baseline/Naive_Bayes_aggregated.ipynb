{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59e97170-ac0b-4b40-b60b-0f55ba622009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "664c6564-9668-4f22-a8bb-f130aea4a48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             context  \\\n",
      "0  Ondertussen is de eerstelijnszone BruZEL al me...   \n",
      "1  Ondertussen is de eerstelijnszone BruZEL al me...   \n",
      "2  Ondertussen is de eerstelijnszone BruZEL al me...   \n",
      "3  Ondertussen is de eerstelijnszone BruZEL al me...   \n",
      "4  Ondertussen is de eerstelijnszone BruZEL al me...   \n",
      "\n",
      "                                            question  statistical  \\\n",
      "0  Zoals alle eerstelijnszones kreeg ook BruZEL h...            0   \n",
      "1                            a)Wat liep er moeilijk?            0   \n",
      "2  Met welke  uitdagingen  werd BruZEL het afgelo...            0   \n",
      "3      Hoe kunnen  die uitdagingen worden aangepakt?            0   \n",
      "4                                b)Wat liep er goed?            0   \n",
      "\n",
      "                        theme    file_name  \\\n",
      "0  Brussel en de Vlaamse Rand  1752898.txt   \n",
      "1  Brussel en de Vlaamse Rand  1752898.txt   \n",
      "2  Brussel en de Vlaamse Rand  1752898.txt   \n",
      "3  Brussel en de Vlaamse Rand  1752898.txt   \n",
      "4  Brussel en de Vlaamse Rand  1752898.txt   \n",
      "\n",
      "                                          clean_text  \n",
      "0  Zoals alle eerstelijnszones kreeg ook BruZEL h...  \n",
      "1                              Wat liep er moeilijk?  \n",
      "2  Met welke uitdagingen werd BruZEL het afgelope...  \n",
      "3       Hoe kunnen die uitdagingen worden aangepakt?  \n",
      "4                                  Wat liep er goed?  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 92503 entries, 0 to 92502\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   context      92010 non-null  object\n",
      " 1   question     92503 non-null  object\n",
      " 2   statistical  92503 non-null  int64 \n",
      " 3   theme        92503 non-null  object\n",
      " 4   file_name    92503 non-null  object\n",
      " 5   clean_text   92503 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 4.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# âœ… 1. Load & Preprocess Data\n",
    "script_dir = os.getcwd() # Ga Ã©Ã©n map omhoog om 'baseline' te verwijderen en ga naar 'Data'\n",
    "project_root = os.path.dirname(script_dir)  # Dit verwijdert 'baseline' van het script_dir\n",
    "data_folder = os.path.join(project_root, \"Data\")\n",
    "\n",
    "# 1. Dataset inladen\n",
    "file_path = os.path.join(data_folder, \"Grote_data_NoDupsLessThemesENnoWords9.xlsx\")\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "#visualize the data\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3becaec1-0000-4b3a-ac9f-31cf0ec39b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after filtering: 92503\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "# Drop unnecessary columns\n",
    "columns_to_drop = [ \"file_name\", \"statistical\"]\n",
    "df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#amount of rows \n",
    "print(f\"Number of rows after filtering: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b56992a7-6c5e-48ce-b12b-5b8dbebe07ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 74002\n",
      "After Random Oversampling: 74002\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Convert text to TF-IDF vectors\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X = vectorizer.fit_transform(df[\"clean_text\"])\n",
    "y = df[\"theme\"]\n",
    "\n",
    "# âœ… Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Original dataset size: {X_train.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "155936a5-2fd0-4c44-bd28-afedc16db86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV wordt uitgevoerd... ðŸš€\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Beste parameters: {'alpha': 0.01}\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "                   Begroting       0.84      0.40      0.54       272\n",
      "           Bestuur en Beleid       0.72      0.52      0.61      1147\n",
      "  Brussel en de Vlaamse Rand       0.91      0.26      0.41       165\n",
      "     Cultuur en Communicatie       0.70      0.42      0.53       629\n",
      "          Economie en Arbeid       0.66      0.61      0.64      1575\n",
      "                     Energie       0.79      0.45      0.57       621\n",
      "                   FinanciÃ«n       0.78      0.53      0.63       233\n",
      "       Internationaal Beleid       0.81      0.50      0.62       390\n",
      "      Justitie en Handhaving       0.87      0.33      0.48       260\n",
      "          Milieu en Landbouw       0.54      0.68      0.60      2906\n",
      "Mobiliteit en Infrastructuur       0.66      0.86      0.75      4985\n",
      "    Onderwijs en Samenleving       0.58      0.63      0.60      2129\n",
      "           Onroerend erfgoed       0.85      0.31      0.45       216\n",
      "                       Sport       0.86      0.19      0.31       102\n",
      "                    Toerisme       0.80      0.34      0.47       292\n",
      "       Welzijn en Gezondheid       0.63      0.56      0.60      1913\n",
      "     Wetenschap en Innovatie       0.60      0.07      0.12        44\n",
      "                       Wonen       0.73      0.47      0.57       622\n",
      "\n",
      "                    accuracy                           0.64     18501\n",
      "                   macro avg       0.74      0.45      0.53     18501\n",
      "                weighted avg       0.66      0.64      0.63     18501\n",
      "\n",
      "      Metric     Score\n",
      "0   Accuracy  0.639533\n",
      "1  Precision  0.659209\n",
      "2     Recall  0.639533\n",
      "3         F1  0.629457\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    MultinomialNB(),\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_weighted',\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 4. Fit (X_train must be raw text!)\n",
    "print(\"GridSearchCV wordt uitgevoerd... ðŸš€\")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# 5. Predict on test set\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "\n",
    "print(f\"Beste parameters: {grid.best_params_}\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# 7. Summary table\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=\"weighted\", zero_division=1)\n",
    "\n",
    "baseline_results = pd.DataFrame({\n",
    "    \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1\"],\n",
    "    \"Score\": [accuracy, precision, recall, f1]\n",
    "})\n",
    "\n",
    "print(baseline_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5046efda-5387-49a3-8e19-b08e80d9586e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
