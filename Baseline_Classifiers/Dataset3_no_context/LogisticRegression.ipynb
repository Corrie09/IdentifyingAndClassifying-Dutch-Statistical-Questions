{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7410b026-af28-4d8d-8409-1210b2f944d8",
   "metadata": {},
   "source": [
    "**Baseline classifier model. Op basis van TF-IDF Logistische regressie. Moet class imbalance nog aanpakken.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efdbe6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\nwat gebeurd is: eerst GridSearchCV gerund en daarna gezien dat deze configuratie met l1 dus de beste is\"\\ndaarna dus de l1 configuratie gebruikt en de beste parameters nog aan het zoeken\"\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "wat gebeurd is: eerst GridSearchCV gerund en daarna gezien dat deze configuratie met l1 dus de beste is\"\n",
    "daarna dus de l1 configuratie gebruikt en de beste parameters nog aan het zoeken\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38ea7584-6167-4c51-9619-0dfedff4f485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cfc791d-5b32-4ae9-9440-c3b62b0aa114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             context  \\\n",
      "0  Ondertussen is de eerstelijnszone BruZEL al me...   \n",
      "1  Ondertussen is de eerstelijnszone BruZEL al me...   \n",
      "2  Ondertussen is de eerstelijnszone BruZEL al me...   \n",
      "3  Ondertussen is de eerstelijnszone BruZEL al me...   \n",
      "4  Ondertussen is de eerstelijnszone BruZEL al me...   \n",
      "\n",
      "                                            question  statistical  \\\n",
      "0  Zoals alle eerstelijnszones kreeg ook BruZEL h...            0   \n",
      "1  2.Kan de minister toelichten op welke manier B...            0   \n",
      "2  3.Kan de minister in het bijzonder toelichten ...            0   \n",
      "3  4.Kan de minister in het bijzonder toelichten ...            0   \n",
      "4  Zoals alle eerstelijnszones kreeg ook BruZEL h...            0   \n",
      "\n",
      "                        theme    file_name  \\\n",
      "0  Brussel en de Vlaamse Rand  1752898.txt   \n",
      "1  Brussel en de Vlaamse Rand  1752898.txt   \n",
      "2  Brussel en de Vlaamse Rand  1752898.txt   \n",
      "3  Brussel en de Vlaamse Rand  1752898.txt   \n",
      "4  Brussel en de Vlaamse Rand  1752906.txt   \n",
      "\n",
      "                                          clean_text  \n",
      "0  Zoals alle eerstelijnszones kreeg ook BruZEL h...  \n",
      "1  Kan de minister toelichten op welke manier Bru...  \n",
      "2  Kan de minister in het bijzonder toelichten op...  \n",
      "3  Kan de minister in het bijzonder toelichten op...  \n",
      "4  Zoals alle eerstelijnszones kreeg ook BruZEL h...  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64572 entries, 0 to 64571\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   context      64262 non-null  object\n",
      " 1   question     64572 non-null  object\n",
      " 2   statistical  64572 non-null  int64 \n",
      " 3   theme        64572 non-null  object\n",
      " 4   file_name    64572 non-null  object\n",
      " 5   clean_text   64572 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 3.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# âœ… 1. Load & Preprocess Data\n",
    "script_dir = os.path.dirname(os.getcwd())# Ga Ã©Ã©n map omhoog om 'baseline' te verwijderen en ga naar 'Data'\n",
    "project_root = os.path.dirname(script_dir)  # Dit verwijdert 'baseline' van het script_dir\n",
    "data_folder = os.path.join(project_root, \"Data\")\n",
    "\n",
    "# 1. Dataset inladen\n",
    "file_path = os.path.join(data_folder, \"Grote_data_NoDupsLessThemesENnoWords9.xlsx\")\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "#visualize the data\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "394b4a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after filtering: 64572\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "# Drop unnecessary columns\n",
    "# Drop unnecessary columns\n",
    "columns_to_drop = [\"context\",\"file_name\",\"question\",\"statistical\"]\n",
    "df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "\n",
    "# âœ… Drop rare themes (appearing < 2 times)\n",
    "theme_counts = df[\"theme\"].value_counts()\n",
    "valid_themes = theme_counts[theme_counts >= 100].index\n",
    "df = df[df[\"theme\"].isin(valid_themes)]\n",
    "\n",
    "\n",
    "\n",
    "# Amount of rows\n",
    "print(f\"Number of rows after filtering: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efbf57e8-8df5-44e7-9adf-d0dca0d2a095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jefva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. Encode labels\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df[\"theme\"])\n",
    "X = df[\"clean_text\"]  \n",
    "\n",
    "# 2. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 3. TF-IDF vectorization with Dutch stopwords and bigrams\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "dutch_stopwords = stopwords.words(\"dutch\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),\n",
    "    max_features=10000,\n",
    "    stop_words=dutch_stopwords\n",
    ")\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7c7b2e3-b6b9-4ebc-85a9-5ed73d65e256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV wordt uitgevoerd... ðŸš€\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Beste parameters: {'C': 10, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.69       171\n",
      "           1       0.56      0.66      0.61       829\n",
      "           2       0.14      0.72      0.23       112\n",
      "           3       0.56      0.54      0.55       465\n",
      "           4       0.67      0.64      0.66      1039\n",
      "           5       0.55      0.63      0.59       442\n",
      "           6       0.36      0.71      0.48       157\n",
      "           7       0.44      0.66      0.52       280\n",
      "           8       0.41      0.53      0.46       172\n",
      "           9       0.67      0.55      0.61      2006\n",
      "          10       0.91      0.70      0.79      3433\n",
      "          11       0.74      0.54      0.62      1543\n",
      "          12       0.35      0.58      0.43       152\n",
      "          13       0.10      0.43      0.17        81\n",
      "          14       0.53      0.48      0.50       215\n",
      "          15       0.52      0.65      0.58      1328\n",
      "          16       0.00      0.00      0.00        32\n",
      "          17       0.63      0.56      0.59       458\n",
      "\n",
      "    accuracy                           0.62     12915\n",
      "   macro avg       0.49      0.57      0.50     12915\n",
      "weighted avg       0.68      0.62      0.64     12915\n",
      "\n",
      "      Metric     Score\n",
      "0   Accuracy  0.620364\n",
      "1  Precision  0.683898\n",
      "2     Recall  0.620364\n",
      "3         F1  0.639151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jefva\\anaconda3\\envs\\bert_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# âœ… Hyperparameter tuning met GridSearchCV\n",
    "# Conditional grid - alleen 'elasticnet' krijgt l1_ratio\n",
    "param_grid = {\n",
    "    'C': [0.1,1,10],  # Minder waarden testen\n",
    "    'penalty': ['l2'],  # ElasticNet weglaten als dat niet veel verschil maakt\n",
    "    'solver': ['saga'],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    LogisticRegression(max_iter=500),  # Model\n",
    "    param_grid,  # Zoekruimte\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring=\"f1_weighted\",  # Optimaliseer voor F1-score\n",
    "    n_jobs=-1,  # Parallel berekenen\n",
    "    verbose=2  # âœ… Geeft gedetailleerde logs per iteratie\n",
    ")\n",
    "\n",
    "# 4. Fit (X_train must be raw text!)\n",
    "print(\"GridSearchCV wordt uitgevoerd... ðŸš€\")\n",
    "grid.fit(X_train_vec, y_train)\n",
    "\n",
    "# 5. Predict on test set\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# 7. Predict + decode\n",
    "y_pred = best_model.predict(X_test_vec)\n",
    "y_test_labels = le.inverse_transform(y_test)\n",
    "y_pred_labels = le.inverse_transform(y_pred)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Beste parameters: {grid.best_params_}\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# 7. Summary table\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=\"weighted\", zero_division=1)\n",
    "\n",
    "baseline_results = pd.DataFrame({\n",
    "    \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1\"],\n",
    "    \"Score\": [accuracy, precision, recall, f1]\n",
    "})\n",
    "\n",
    "print(baseline_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b663f8b1-55b7-4db8-8a76-487c75c74975",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
