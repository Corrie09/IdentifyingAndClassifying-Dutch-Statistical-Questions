{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Andere manier om te kijken naar evaluation, i.p.v terug te splitten en te predicten, nu opgeslagen predicition gebruiken**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\corne\\anaconda3\\envs\\thesis-env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30073, 768, padding_idx=3)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Path to the saved model directory\n",
    "save_path = r\"C:\\Users\\corne\\OneDrive - KU Leuven\\Thesis\\Working Code\\SAVED-Models\\GroNLP\\Run_2025-04-23_18-28\"\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(save_path)\n",
    "model = BertForSequenceClassification.from_pretrained(save_path)\n",
    "model.eval()  # Set to eval mode\n",
    "\n",
    "# Optional: Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import json  # Needed for loading the mappings\n",
    "\n",
    "# === Define path to the saved run ===\n",
    "save_path = r\"C:\\Users\\corne\\OneDrive - KU Leuven\\Thesis\\Working Code\\SAVED-Models\\GroNLP\\Run_2025-04-23_18-28\"\n",
    "\n",
    "# âœ… Load the saved test predictions \n",
    "df = pd.read_csv(os.path.join(save_path, \"test_predictions.csv\"))\n",
    "\n",
    "# âœ… Recreate logits tensor from the CSV\n",
    "logits = torch.tensor(df[\"logits\"].apply(eval).tolist())\n",
    "\n",
    "# âœ… Apply softmax to get prediction probabilities\n",
    "probabilities = F.softmax(logits, dim=1)\n",
    "\n",
    "# âœ… Extract raw values\n",
    "texts = df[\"text\"].tolist()\n",
    "true_labels_ids = df[\"true_label\"].tolist()\n",
    "predicted_label_ids = df[\"predicted_label\"].tolist()\n",
    "\n",
    "# âœ… Convert label IDs to themes using the mappings\n",
    "with open(os.path.join(save_path, \"label_mappings.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    mappings = json.load(f)\n",
    "\n",
    "theme_to_id = mappings[\"theme_to_id\"]\n",
    "id_to_theme = {int(k): v for k, v in mappings[\"id_to_theme\"].items()}  # convert keys back to int\n",
    "unique_themes = mappings[\"unique_themes\"]  # Load the unique themes list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Random Misclassified Examples (confidence 0.60â€“0.99):\n",
      "\n",
      "ID 6717 | True: Cultuur en Communicatie | Pred: Onderwijs en Samenleving | Conf: 0.99\n",
      "â†’ Uit hoeveel mensen zal de afdeling Digitalisering bestaan, wie zal ze leiden en wanneer moet ze operationeel zijn?\n",
      "\n",
      "ID 5229 | True: Toerisme | Pred: Bestuur en Beleid | Conf: 0.60\n",
      "â†’ Hoeveel van de klachten overgemaakt aan de Vlaamse Ombudsdienst werden ontvankelijk verklaard?\n",
      "\n",
      "ID 9018 | True: Bestuur en Beleid | Pred: Milieu en Landbouw | Conf: 0.83\n",
      "â†’ Hoe apprecieert de minister die cijfers? Zo ja, wat zijn volgens de minister daarvan de oorzaken?\n",
      "\n",
      "ID 1022 | True: Milieu en Landbouw | Pred: Welzijn en Gezondheid | Conf: 0.62\n",
      "â†’ Heeft de minister daarover een evaluatie gemaakt? Zo ja, wat waren de bevindingen van de minister?\n",
      "\n",
      "ID 5784 | True: Milieu en Landbouw | Pred: Mobiliteit en Infrastructuur | Conf: 0.96\n",
      "â†’ Kan zij per actie het volgende specifiÃ«ren: naam van de maatregel; doelstelling van de maatregel; verantwoordelijke administratie; stand van zaken: gestart, in uitvoering, uitgevoerd, graag nader gespecifieerd naar soort communicatiecampagne; link naar de communicatiecampagne of sensibilisatiecampag\n",
      "\n",
      "âœ… Random Correctly Classified Examples (confidence 0.60â€“0.99):\n",
      "\n",
      "ID 6985 | True: Begroting | Pred: Begroting | Conf: 0.97\n",
      "â†’ Hoeveel middelen uit de centrale relanceprovisie werden effectief herverdeeld naar de beleidsdomeinen?\n",
      "\n",
      "ID 5197 | True: Justitie en Handhaving | Pred: Justitie en Handhaving | Conf: 0.99\n",
      "â†’ Hoeveel gedetineerden hebben het afgelopen jaar gebruikgemaakt van het onderwijsaanbod in de gevangenis?\n",
      "\n",
      "ID 510 | True: Mobiliteit en Infrastructuur | Pred: Mobiliteit en Infrastructuur | Conf: 0.93\n",
      "â†’ Waarom komen enkel zero-emissietweedehandswagens ouder dan 3 jaar in aanmerking voor de premie?\n",
      "\n",
      "ID 6140 | True: Milieu en Landbouw | Pred: Milieu en Landbouw | Conf: 0.97\n",
      "â†’ De minister gaf aan tegen eind 2022 te werken aan een tussentijdse doelstelling in de aanloop naar Kan de minister aangeven hoe het proces verloopt om tot deze tussentijdse doelstellingen te komen?\n",
      "\n",
      "ID 7700 | True: Begroting | Pred: Begroting | Conf: 0.97\n",
      "â†’ Hoeveel crisisuitgaven verwacht de minister nog gelet op reeds genomen of nog verwachte beslissingen?\n"
     ]
    }
   ],
   "source": [
    "# Filter confidence range first\n",
    "wrong_pool = data[\n",
    "    (data[\"correct\"] == False) &\n",
    "    (data[\"confidence\"] >= 0.60) &\n",
    "    (data[\"confidence\"] < 0.99)\n",
    "]\n",
    "\n",
    "right_pool = data[\n",
    "    (data[\"correct\"] == True) &\n",
    "    (data[\"confidence\"] >= 0.60) &\n",
    "    (data[\"confidence\"] < 0.99)\n",
    "]\n",
    "\n",
    "# Sample randomly from filtered sets\n",
    "wrong_filtered = wrong_pool.sample(n=5, random_state=42)\n",
    "right_filtered = right_pool.sample(n=5, random_state=24)\n",
    "\n",
    "# Display for confirmation\n",
    "print(\"âŒ Random Misclassified Examples (confidence 0.60â€“0.99):\")\n",
    "for i, row in wrong_filtered.iterrows():\n",
    "    print(f\"\\nID {i} | True: {row['true_theme']} | Pred: {row['pred_theme']} | Conf: {row['confidence']:.2f}\")\n",
    "    print(f\"â†’ {row['text'][:300]}\")\n",
    "\n",
    "print(\"\\nâœ… Random Correctly Classified Examples (confidence 0.60â€“0.99):\")\n",
    "for i, row in right_filtered.iterrows():\n",
    "    print(f\"\\nID {i} | True: {row['true_theme']} | Pred: {row['pred_theme']} | Conf: {row['confidence']:.2f}\")\n",
    "    print(f\"â†’ {row['text'][:300]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(texts):\n",
    "    encoded = tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    input_ids = encoded[\"input_ids\"].to(device)\n",
    "    attention_mask = encoded[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        probs = F.softmax(outputs.logits, dim=1)\n",
    "\n",
    "    return probs.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” ID 5229 | WRONG prediction\n",
      "â†’ True: Toerisme\n",
      "â†’ Predicted: Bestuur en Beleid\n",
      "â†’ Confidence: 0.60\n",
      "â†’ Text: Hoeveel van de klachten overgemaakt aan de Vlaamse Ombudsdienst werden ontvankelijk verklaard?\n",
      "\n",
      "âœ… Saved LIME explanation to: lime_explanations\\wrong_id5229_Bestuur_en_Beleid_vs_Toerisme.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import os\n",
    "\n",
    "# Setup LIME explainer\n",
    "class_names = [id_to_theme[i] for i in sorted(id_to_theme.keys())]\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "# Folder to save explanations\n",
    "lime_output_dir = \"lime_explanations\"\n",
    "os.makedirs(lime_output_dir, exist_ok=True)\n",
    "\n",
    "# Combine both sets\n",
    "all_examples = pd.concat([\n",
    "    wrong_filtered.assign(type=\"wrong\"),\n",
    "    right_filtered.assign(type=\"correct\")\n",
    "])\n",
    "# === Specify the ID of the example you want to explain ===\n",
    "example_id = 5229  # ðŸ‘ˆ change this to whatever ID you want\n",
    "\n",
    "# === Fetch the row from the full DataFrame (e.g., `data` or `all_examples`) ===\n",
    "row = data.loc[example_id]  # or all_examples.loc[example_id] if you're using a filtered subset\n",
    "\n",
    "sample_text = row[\"text\"]\n",
    "text_snippet = sample_text[:300].replace(\"\\n\", \" \").strip()\n",
    "true_theme = row[\"true_theme\"]\n",
    "pred_theme = row[\"pred_theme\"]\n",
    "pred_id = row[\"pred_label_id\"]\n",
    "conf = row[\"confidence\"]\n",
    "label_type = \"correct\" if row[\"correct\"] else \"wrong\"\n",
    "\n",
    "print(f\"\\nðŸ” ID {example_id} | {label_type.upper()} prediction\")\n",
    "print(f\"â†’ True: {true_theme}\")\n",
    "print(f\"â†’ Predicted: {pred_theme}\")\n",
    "print(f\"â†’ Confidence: {conf:.2f}\")\n",
    "print(f\"â†’ Text: {text_snippet}\")\n",
    "\n",
    "# Run LIME\n",
    "explanation = explainer.explain_instance(\n",
    "    sample_text,\n",
    "    predict_proba,\n",
    "    num_features=10,\n",
    "    labels=[pred_id],\n",
    "    num_samples=1000\n",
    ")\n",
    "\n",
    "# Save to file\n",
    "safe_pred = pred_theme.replace(\" \", \"_\").replace(\"/\", \"-\")\n",
    "safe_true = true_theme.replace(\" \", \"_\").replace(\"/\", \"-\")\n",
    "filename = f\"{label_type}_id{example_id}_{safe_pred}_vs_{safe_true}.html\"\n",
    "path = os.path.join(lime_output_dir, filename)\n",
    "explanation.save_to_file(path)\n",
    "\n",
    "print(f\"\\nâœ… Saved LIME explanation to: {path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
