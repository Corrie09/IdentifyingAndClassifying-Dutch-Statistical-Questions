{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02f802ec-808c-4c4e-b6da-7d0e38ab4de0",
   "metadata": {},
   "source": [
    "**Bert model op basis van Bert van Universiteit van Groningen. Context handling moet nog aangepast worden. Oversampling a.d.h.v de mediaan. dynamisch treshhold zoeken voor unknown.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24278f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\corne\\anaconda3\\envs\\thesis-env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import torch.nn.functional as F\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ce9fa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 1. Load & Preprocess Data\n",
    "script_dir = os.getcwd() # Ga één map omhoog om 'baseline' te verwijderen en ga naar 'Data'\n",
    "project_root = os.path.dirname(script_dir)  # Dit verwijdert 'baseline' van het script_dir\n",
    "data_folder = os.path.join(project_root, \"Data\")\n",
    "\n",
    "# 1. Dataset inladen\n",
    "file_path = os.path.join(data_folder, \"Grote_data.xlsx\")\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90b18e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_2776\\2837290246.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"context\"].fillna(\"\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "if \"TXT_file_name\" in df.columns:\n",
    "    df = df.drop(columns=[\"TXT_file_name\"])\n",
    "\n",
    "# Handle missing values\n",
    "df = df.dropna(subset=[\"question\"])\n",
    "df[\"context\"].fillna(\"\", inplace=True)\n",
    "\n",
    "# Clean text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    text = re.sub(r'\\b[a-z]\\)\\s+', ' ', text)\n",
    "    text = re.sub(r'\\b\\d+\\.\\b', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df[\"clean_text\"] = (df[\"context\"] + \" \" + df[\"question\"]).apply(clean_text)\n",
    "\n",
    "# ✅ Now: drop rare themes using original theme names\n",
    "theme_counts = df[\"theme\"].value_counts()\n",
    "valid_themes = theme_counts[theme_counts >= 2].index\n",
    "df = df[df[\"theme\"].isin(valid_themes)]\n",
    "\n",
    "# ✅ Recompute label encoding AFTER filtering\n",
    "unique_themes = list(df[\"theme\"].unique())\n",
    "theme_to_id = {theme: idx for idx, theme in enumerate(unique_themes)}\n",
    "id_to_theme = {idx: theme for theme, idx in theme_to_id.items()}\n",
    "df[\"theme_id\"] = df[\"theme\"].map(theme_to_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcb6cbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All theme_ids: [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11), np.int64(12), np.int64(13), np.int64(14), np.int64(15), np.int64(16), np.int64(17), np.int64(18), np.int64(19), np.int64(20), np.int64(21), np.int64(22), np.int64(23), np.int64(24), np.int64(25), np.int64(26), np.int64(27), np.int64(28), np.int64(29), np.int64(30), np.int64(31), np.int64(32), np.int64(33), np.int64(34), np.int64(35), np.int64(36)]\n",
      "num_labels: 37\n"
     ]
    }
   ],
   "source": [
    "print(\"All theme_ids:\", sorted(df[\"theme_id\"].unique()))\n",
    "print(\"num_labels:\", df[\"theme_id\"].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ed805a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 5. Split Data into Train & Test\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df[\"clean_text\"].tolist(), df[\"theme_id\"].tolist(), test_size=0.2, random_state=42, stratify=df[\"theme_id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2626eb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after oversampling: Counter({15: 5147, 4: 1763, 9: 1699, 26: 1216, 12: 1124, 6: 949, 21: 860, 0: 855, 20: 736, 16: 641, 28: 622, 14: 612, 8: 553, 1: 527, 17: 433, 23: 332, 22: 330, 11: 323, 31: 253, 27: 253, 25: 253, 5: 253, 24: 253, 2: 253, 19: 253, 29: 253, 18: 253, 13: 253, 7: 253, 3: 253, 32: 253, 10: 253, 30: 253, 33: 253, 34: 253, 35: 253, 36: 253})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pandas as pd\n",
    "\n",
    "# Create a small DataFrame from train lists\n",
    "train_df = pd.DataFrame({\n",
    "    \"clean_text\": train_texts,\n",
    "    \"theme_id\": train_labels\n",
    "})\n",
    "\n",
    "# Compute class counts and use median as balancing target\n",
    "theme_counts = train_df[\"theme_id\"].value_counts()\n",
    "median_count = theme_counts.median()\n",
    "\n",
    "# Define strategy: only oversample underrepresented classes\n",
    "sampling_strategy = {\n",
    "    theme: int(median_count)\n",
    "    for theme in theme_counts.index\n",
    "    if theme_counts[theme] < median_count\n",
    "}\n",
    "\n",
    "# Apply RandomOverSampler\n",
    "ros = RandomOverSampler(sampling_strategy=sampling_strategy, random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(train_df[[\"clean_text\"]], train_df[\"theme_id\"])\n",
    "\n",
    "# Extract oversampled train lists\n",
    "train_texts_resampled = X_resampled[\"clean_text\"].tolist()\n",
    "train_labels_resampled = y_resampled.tolist()\n",
    "\n",
    "from collections import Counter\n",
    "print(\"Class distribution after oversampling:\", Counter(train_labels_resampled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b392dad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 7. Load BERT Tokenizer & Define Dataset Class\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "\n",
    "model_name = \"pdelobelle/robbert-v2-dutch-base\"\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "\n",
    "class ThemeDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx], padding=\"max_length\", truncation=True, max_length=self.max_length, return_tensors=\"pt\"\n",
    "        )\n",
    "        encoding[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "\n",
    "train_dataset = ThemeDataset(train_texts_resampled, train_labels_resampled, tokenizer)\n",
    "test_dataset = ThemeDataset(test_texts, test_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ebcd1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# ✅ 8. Load BERT Model for Classification\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=df[\"theme_id\"].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7423c6f4-03c2-42c7-93bd-ca27f376ee2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\corne\\anaconda3\\envs\\thesis-env\\lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      " 12%|█▎        | 2942/23536 [10:15<1:06:47,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3515, 'grad_norm': 27.846521377563477, 'learning_rate': 1.7501699524133243e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      " 12%|█▎        | 2942/23536 [10:45<1:06:47,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6786455512046814, 'eval_accuracy': 0.8241758241758241, 'eval_precision': 0.8336463068787837, 'eval_recall': 0.8241758241758241, 'eval_f1': 0.8229507158732067, 'eval_runtime': 30.6134, 'eval_samples_per_second': 172.408, 'eval_steps_per_second': 21.559, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5884/23536 [21:02<1:00:34,  4.86it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4925, 'grad_norm': 0.1165366917848587, 'learning_rate': 1.5003399048266487e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      " 25%|██▌       | 5884/23536 [21:32<1:00:34,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5015876293182373, 'eval_accuracy': 0.8776051534672225, 'eval_precision': 0.8867036857933203, 'eval_recall': 0.8776051534672225, 'eval_f1': 0.8782040652833458, 'eval_runtime': 30.2679, 'eval_samples_per_second': 174.376, 'eval_steps_per_second': 21.805, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 8826/23536 [31:43<51:16,  4.78it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3025, 'grad_norm': 0.023388003930449486, 'learning_rate': 1.2504248810333108e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 38%|███▊      | 8826/23536 [32:13<51:16,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4603025019168854, 'eval_accuracy': 0.8940886699507389, 'eval_precision': 0.9114146181419406, 'eval_recall': 0.8940886699507389, 'eval_f1': 0.8977124678982787, 'eval_runtime': 30.2154, 'eval_samples_per_second': 174.679, 'eval_steps_per_second': 21.843, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 11768/23536 [42:25<40:15,  4.87it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2241, 'grad_norm': 0.0574980229139328, 'learning_rate': 1.0005098572399729e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 50%|█████     | 11768/23536 [42:55<40:15,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.48633959889411926, 'eval_accuracy': 0.9016672982190224, 'eval_precision': 0.9158401616016495, 'eval_recall': 0.9016672982190224, 'eval_f1': 0.9048897900693805, 'eval_runtime': 30.2001, 'eval_samples_per_second': 174.768, 'eval_steps_per_second': 21.854, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 14710/23536 [53:07<30:21,  4.85it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1865, 'grad_norm': 0.45650026202201843, 'learning_rate': 7.5067980965329715e-06, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 62%|██████▎   | 14710/23536 [53:37<30:21,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.45865827798843384, 'eval_accuracy': 0.8997726411519515, 'eval_precision': 0.9048167034086944, 'eval_recall': 0.8997726411519515, 'eval_f1': 0.8992530812789663, 'eval_runtime': 30.239, 'eval_samples_per_second': 174.543, 'eval_steps_per_second': 21.826, 'epoch': 5.0}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:626] . unexpected pos 566691072 vs 566690964",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\corne\\anaconda3\\envs\\thesis-env\\lib\\site-packages\\torch\\serialization.py:944\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m    943\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m--> 944\u001b[0m     \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    951\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\corne\\anaconda3\\envs\\thesis-env\\lib\\site-packages\\torch\\serialization.py:1216\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# Now that it is on the CPU we can directly copy it into the zip file\u001b[39;00m\n\u001b[1;32m-> 1216\u001b[0m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:820] . PytorchStreamWriter failed writing file data/202: file write failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 37\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# ✅ 11. Train Model with Early Stopping\u001b[39;00m\n\u001b[0;32m     28\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     29\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     30\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[EarlyStoppingCallback(early_stopping_patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)]  \u001b[38;5;66;03m# Stop if no improvement for 2 epochs\u001b[39;00m\n\u001b[0;32m     35\u001b[0m )\n\u001b[1;32m---> 37\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\corne\\anaconda3\\envs\\thesis-env\\lib\\site-packages\\transformers\\trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\corne\\anaconda3\\envs\\thesis-env\\lib\\site-packages\\transformers\\trainer.py:2573\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   2572\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m-> 2573\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[0;32m   2576\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_xla_available():\n\u001b[0;32m   2577\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\corne\\anaconda3\\envs\\thesis-env\\lib\\site-packages\\transformers\\trainer.py:3007\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[1;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   3004\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate(trial, ignore_keys_for_eval)\n\u001b[0;32m   3006\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[1;32m-> 3007\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3008\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[1;32mc:\\Users\\corne\\anaconda3\\envs\\thesis-env\\lib\\site-packages\\transformers\\trainer.py:3101\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[1;34m(self, model, trial, metrics)\u001b[0m\n\u001b[0;32m   3097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model(output_dir, _internal_call\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   3099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_only_model:\n\u001b[0;32m   3100\u001b[0m     \u001b[38;5;66;03m# Save optimizer and scheduler\u001b[39;00m\n\u001b[1;32m-> 3101\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_optimizer_and_scheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3102\u001b[0m     \u001b[38;5;66;03m# Save RNG state\u001b[39;00m\n\u001b[0;32m   3103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_rng_state(output_dir)\n",
      "File \u001b[1;32mc:\\Users\\corne\\anaconda3\\envs\\thesis-env\\lib\\site-packages\\transformers\\trainer.py:3247\u001b[0m, in \u001b[0;36mTrainer._save_optimizer_and_scheduler\u001b[1;34m(self, output_dir)\u001b[0m\n\u001b[0;32m   3242\u001b[0m     save_fsdp_optimizer(\n\u001b[0;32m   3243\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfsdp_plugin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, output_dir\n\u001b[0;32m   3244\u001b[0m     )\n\u001b[0;32m   3245\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m   3246\u001b[0m     \u001b[38;5;66;03m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[39;00m\n\u001b[1;32m-> 3247\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOPTIMIZER_NAME\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3249\u001b[0m \u001b[38;5;66;03m# Save SCHEDULER & SCALER\u001b[39;00m\n\u001b[0;32m   3250\u001b[0m is_deepspeed_custom_scheduler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_deepspeed_enabled \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m   3251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler, DeepSpeedSchedulerWrapper\n\u001b[0;32m   3252\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\corne\\anaconda3\\envs\\thesis-env\\lib\\site-packages\\torch\\serialization.py:951\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m    943\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m    944\u001b[0m         _save(\n\u001b[0;32m    945\u001b[0m             obj,\n\u001b[0;32m    946\u001b[0m             opened_zipfile,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    949\u001b[0m             _disable_byteorder_record,\n\u001b[0;32m    950\u001b[0m         )\n\u001b[1;32m--> 951\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    953\u001b[0m     \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n",
      "File \u001b[1;32mc:\\Users\\corne\\anaconda3\\envs\\thesis-env\\lib\\site-packages\\torch\\serialization.py:784\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__exit__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 784\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_end_of_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    786\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:626] . unexpected pos 566691072 vs 566690964"
     ]
    }
   ],
   "source": [
    "# ✅ 9. Define Training Arguments (With Early Stopping)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=8,  \n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_strategy=\"epoch\",  # 🔥 Log only once per epoch\n",
    "    fp16=True,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True\n",
    ")\n",
    "\n",
    "# ✅ 10. Define Metrics for Evaluation\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\", zero_division=1)\n",
    "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "# ✅ 11. Train Model with Early Stopping\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]  # Stop if no improvement for 2 epochs\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4e3fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model and tokenizer\n",
    "model.save_pretrained(\"./ImprovedModelroBERTa\")\n",
    "tokenizer.save_pretrained(\"./ImprovedModelroBERTa\")\n",
    "# Save the model configuration\n",
    "model.config.save_pretrained(\"./ImprovedModelroBERTa\")\n",
    "# Save the mapping of theme IDs to themes\n",
    "with open(\"./final_model/theme_mapping.txt\", \"w\") as f:\n",
    "    for theme_id, theme in id_to_theme.items():\n",
    "        f.write(f\"{theme_id}\\t{theme}\\n\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738e3d03",
   "metadata": {},
   "source": [
    "EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e250902",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc92c427",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predictions.predictions.argmax(axis=1)\n",
    "y_true = predictions.label_ids\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "all_labels = sorted(id_to_theme.keys())  # [0, 1, 2, ..., 34]\n",
    "all_names = [id_to_theme[i] for i in all_labels]\n",
    "\n",
    "print(classification_report(y_true, y_pred, labels=all_labels, target_names=all_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0416812a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=id_to_theme.values(), yticklabels=id_to_theme.values(), cbar=True)\n",
    "plt.xlabel(\"Predicted Labels\", fontsize=14)\n",
    "plt.ylabel(\"True Labels\", fontsize=14)\n",
    "plt.title(\"Confusion Matrix\", fontsize=16)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xticks(rotation=30, ha=\"right\", fontsize=10)  # Rotate x-axis labels slightly\n",
    "plt.yticks(fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32184c57",
   "metadata": {},
   "source": [
    "Handle extremely short or vague questions by labeling them \"Unknown\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e68926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 13. Make Predictions (With Dynamic Confidence Threshold & Short Question Handling)\n",
    "predictions = trainer.predict(test_dataset)\n",
    "probabilities = F.softmax(torch.tensor(predictions.predictions), dim=1)\n",
    "\n",
    "# ✅ Dynamically Adjust the Confidence Threshold (1st Percentile)\n",
    "confidence_values = torch.max(probabilities, dim=1)[0].tolist()\n",
    "dynamic_threshold = np.percentile(confidence_values, 1)  # ✅ Set threshold at the 5th percentile\n",
    "print(f\"Dynamic Threshold: {dynamic_threshold}\")  # ✅ Print the new threshold\n",
    "\n",
    "# ✅ Predict Themes with \"Unknown\" for Unclear Questions\n",
    "predicted_labels = []\n",
    "for i in range(len(probabilities)):\n",
    "    max_prob = torch.max(probabilities[i]).item()\n",
    "    pred_label = torch.argmax(probabilities[i]).item()\n",
    "    question_text = test_texts[i]\n",
    "\n",
    "    # ✅ If question is too short and lacks context, assign \"Unknown\"\n",
    "    if len(question_text.split()) < 4:\n",
    "        predicted_labels.append(\"Unknown\")\n",
    "    elif max_prob < dynamic_threshold:\n",
    "        predicted_labels.append(\"Unknown\")  # ✅ Filter out low-confidence predictions\n",
    "    else:\n",
    "        predicted_labels.append(id_to_theme[pred_label])  # ✅ Assign label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43ffbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_count = predicted_labels.count(\"Unknown\")\n",
    "print(f\"Unknown predictions: {unknown_count} / {len(predicted_labels)} ({unknown_count/len(predicted_labels)*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023fc296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 14. Save Predictions \n",
    "output_df = pd.DataFrame({\n",
    "    \"Text\": test_texts,\n",
    "    \"True_Theme\": [id_to_theme[label] for label in test_labels],\n",
    "    \"Predicted_Theme\": predicted_labels\n",
    "})\n",
    "output_df[\"Correct\"] = output_df[\"True_Theme\"] == output_df[\"Predicted_Theme\"]\n",
    "output_df[\"Was_Unknown\"] = output_df[\"Predicted_Theme\"] == \"Unknown\"\n",
    "\n",
    "\n",
    "output_df.to_excel(\"BertGroNLP-theme_classification.xlsx\", index=False)\n",
    "print(\"✅ Model Training Completed! Predictions saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3a9947-7d3f-4a26-bd4e-87f4b0659dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 15. Visualize Distribution of Predicted Themes\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# ✅ Replace this with your actual predictions DataFrame\n",
    "# Example: If your predictions are stored in a variable `predicted_labels`\n",
    "# Convert it into a DataFrame for visualization\n",
    "df = pd.DataFrame({\"Predicted_Theme\": predicted_labels})\n",
    "\n",
    "# ✅ Count occurrences of each predicted theme\n",
    "label_counts = df[\"Predicted_Theme\"].value_counts()\n",
    "\n",
    "# ✅ Create the bar plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=label_counts.index, y=label_counts.values)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"Predicted Theme\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of Assigned Labels in Model Predictions\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c19499-cb20-491f-8915-0719ff5d96f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e0b2ed8",
   "metadata": {},
   "source": [
    "TO GET ATTENTION SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83e3e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if GPU is available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b451f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention_and_prediction(clean_text):\n",
    "    \"\"\"Extracts attention scores and model prediction for a given question.\"\"\"\n",
    "    model.config.output_attentions = True  # Ensure attention is enabled\n",
    "\n",
    "    # Tokenize input\n",
    "    tokenizer_inputs = tokenizer(clean_text, return_tensors=\"pt\")  \n",
    "    tokenizer_inputs = {key: val.to(device) for key, val in tokenizer_inputs.items()}  # Move to GPU if available\n",
    "\n",
    "    # Forward pass to get attention scores and logits\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokenizer_inputs)\n",
    "\n",
    "    attentions = outputs.attentions  # Extract attention scores\n",
    "    logits = outputs.logits  # Model prediction scores\n",
    "\n",
    "    predicted_class_id = logits.argmax(dim=1).item()  # Get predicted class ID\n",
    "    predicted_class_name = id_to_theme.get(predicted_class_id, \"Unknown\")  # Convert ID to actual class name\n",
    "\n",
    "    return attentions, predicted_class_id, predicted_class_name\n",
    "\n",
    "\n",
    "test_question = \"Hoeveel subsidies zijn toegekend aan bedrijven?\"\n",
    "attention_scores, predicted_class_id, predicted_class_name = get_attention_and_prediction(test_question)\n",
    "\n",
    "print(f\"✅ Model predicted class: {predicted_class_name} (ID: {predicted_class_id})\")\n",
    "print(f\"🔍 Total Attention Layers Extracted: {len(attention_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7de532c-4264-4ad0-9939-14b471ee539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_attention_with_class(question):\n",
    "    \"\"\"Visualizes attention scores and shows the predicted class.\"\"\"\n",
    "    attentions, predicted_class_id, predicted_class_name = get_attention_and_prediction(question)\n",
    "    \n",
    "    num_layers = len(attentions)\n",
    "    layer = num_layers - 1  # Last layer\n",
    "    head = 0  # Choose the first attention head\n",
    "\n",
    "    attention_matrix = attentions[layer][0, head].cpu().numpy()\n",
    "    tokens = tokenizer.tokenize(question)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(attention_matrix, cmap=\"viridis\", aspect=\"auto\")\n",
    "    plt.xticks(range(len(tokens)), tokens, rotation=90)\n",
    "    plt.yticks(range(len(tokens)), tokens)\n",
    "    plt.colorbar(label=\"Attention Score\")\n",
    "    plt.title(f\"Predicted Class: {predicted_class_name} | Attention Heatmap (Layer {layer+1}, Head {head+1})\")\n",
    "    plt.show()\n",
    "\n",
    "correctly_classified_questions = []\n",
    "\n",
    "for _, row in df.sample(100, random_state=42).iterrows():  # Test 100 random samples\n",
    "    question = row[\"clean_text\"]\n",
    "    true_class = row[\"theme\"]  # The actual correct theme\n",
    "\n",
    "    _, predicted_class_id, predicted_class_name = get_attention_and_prediction(question)\n",
    "\n",
    "    if predicted_class_name == true_class:  # ✅ Now we check for correct predictions\n",
    "        correctly_classified_questions.append((question, true_class, predicted_class_name))\n",
    "\n",
    "# Print first few correctly classified questions\n",
    "print(\"✅ Correctly Classified Questions:\")\n",
    "for q, actual, predicted in correctly_classified_questions[:5]:\n",
    "    print(f\"🔍 Question: {q}\")\n",
    "    print(f\"✅ Actual Class: {actual}\")\n",
    "    print(f\"✅ Predicted Class: {predicted}\\n\")\n",
    "\n",
    "# ✅ If there are correct predictions, visualize one\n",
    "if correctly_classified_questions:\n",
    "    sample_correct = correctly_classified_questions[0]  # Pick first correct prediction\n",
    "    question, actual_class, predicted_class = sample_correct\n",
    "\n",
    "    print(f\"✅ Correctly Classified Example:\")\n",
    "    print(f\"🔍 Question: {question}\")\n",
    "    print(f\"✅ Actual Class: {actual_class}\")\n",
    "    print(f\"✅ Predicted Class: {predicted_class}\")\n",
    "\n",
    "    # Visualize attention for correctly classified question\n",
    "    visualize_attention_with_class(question)\n",
    "else:\n",
    "    print(\"❌ No correctly classified questions found in the sample!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abe5b3a-2517-46b9-abf1-4843944317bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# ✅ 1. Load & Preprocess Data\n",
    "script_dir = os.getcwd()\n",
    "project_root = os.path.dirname(script_dir)\n",
    "\n",
    "data_folder = os.path.join(project_root, \"Data\")\n",
    "file_path = os.path.join(data_folder, \"Grote_data.xlsx\")\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Recreate train-test split to match training\n",
    "df_train, df_test = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df[\"theme\"]\n",
    ")\n",
    "\n",
    "# Combine context and question for model input\n",
    "df_test[\"context_question\"] = df_test[\"context\"].astype(str) + \" \" + df_test[\"question\"].astype(str)\n",
    "\n",
    "# ✅ 2. Load fine-tuned model and tokenizer\n",
    "model_path = \"results/checkpoint-8823\"  # Adjust as needed\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"GroNLP/bert-base-dutch-cased\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# ✅ 3. Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# ✅ 4. Function to get CLS embedding\n",
    "def get_cls_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model.bert(**inputs)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "    return cls_embedding.cpu().squeeze().numpy()\n",
    "\n",
    "# ✅ 5. Sample and embed from test set\n",
    "sample_df = df_test.sample(n=2000, random_state=42)\n",
    "embeddings = []\n",
    "\n",
    "print(\"Generating fine-tuned embeddings (from test set)...\")\n",
    "for text in tqdm(sample_df[\"context_question\"]):\n",
    "    emb = get_cls_embedding(text)\n",
    "    embeddings.append(emb)\n",
    "\n",
    "# ✅ 6. UMAP dimensionality reduction\n",
    "print(\"Running UMAP...\")\n",
    "reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, metric='cosine', random_state=42)\n",
    "embedding_2d = reducer.fit_transform(embeddings)\n",
    "\n",
    "# ✅ 7. Plot UMAP\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(sample_df[\"theme\"])\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(embedding_2d[:, 0], embedding_2d[:, 1], c=labels, cmap=\"tab20\", s=10, alpha=0.8)\n",
    "plt.title(\"UMAP of GroNLP BERT Embeddings (After Fine-tuning on Test Set)\")\n",
    "plt.xlabel(\"UMAP-1\")\n",
    "plt.ylabel(\"UMAP-2\")\n",
    "plt.colorbar(scatter, ticks=range(len(le.classes_)), label=\"Theme\")\n",
    "plt.clim(-0.5, len(le.classes_)-0.5)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4d7abe-52df-4539-8637-4f1aaa72b654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7270b9cd-c990-4890-8db4-755e198372ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
