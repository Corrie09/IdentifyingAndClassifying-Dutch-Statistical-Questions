{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02f802ec-808c-4c4e-b6da-7d0e38ab4de0",
   "metadata": {},
   "source": [
    "**Bert model op basis van Bert van Universiteit van Groningen. Context handling moet nog aangepast worden. Oversampling a.d.h.v de mediaan. dynamisch treshhold zoeken voor unknown.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24278f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\corne\\anaconda3\\envs\\thesis-env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import torch.nn.functional as F\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ce9fa61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64572 entries, 0 to 64571\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   context      64262 non-null  object\n",
      " 1   question     64572 non-null  object\n",
      " 2   statistical  64572 non-null  int64 \n",
      " 3   theme        64572 non-null  object\n",
      " 4   file_name    64572 non-null  object\n",
      " 5   clean_text   64572 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 3.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>statistical</th>\n",
       "      <th>theme</th>\n",
       "      <th>file_name</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ondertussen is de eerstelijnszone BruZEL al me...</td>\n",
       "      <td>Zoals alle eerstelijnszones kreeg ook BruZEL h...</td>\n",
       "      <td>0</td>\n",
       "      <td>Brussel en de Vlaamse Rand</td>\n",
       "      <td>1752898.txt</td>\n",
       "      <td>Zoals alle eerstelijnszones kreeg ook BruZEL h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ondertussen is de eerstelijnszone BruZEL al me...</td>\n",
       "      <td>2.Kan de minister toelichten op welke manier B...</td>\n",
       "      <td>0</td>\n",
       "      <td>Brussel en de Vlaamse Rand</td>\n",
       "      <td>1752898.txt</td>\n",
       "      <td>Kan de minister toelichten op welke manier Bru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ondertussen is de eerstelijnszone BruZEL al me...</td>\n",
       "      <td>3.Kan de minister in het bijzonder toelichten ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Brussel en de Vlaamse Rand</td>\n",
       "      <td>1752898.txt</td>\n",
       "      <td>Kan de minister in het bijzonder toelichten op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ondertussen is de eerstelijnszone BruZEL al me...</td>\n",
       "      <td>4.Kan de minister in het bijzonder toelichten ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Brussel en de Vlaamse Rand</td>\n",
       "      <td>1752898.txt</td>\n",
       "      <td>Kan de minister in het bijzonder toelichten op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ondertussen is de eerstelijnszone BruZEL al me...</td>\n",
       "      <td>Zoals alle eerstelijnszones kreeg ook BruZEL h...</td>\n",
       "      <td>0</td>\n",
       "      <td>Brussel en de Vlaamse Rand</td>\n",
       "      <td>1752906.txt</td>\n",
       "      <td>Zoals alle eerstelijnszones kreeg ook BruZEL h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  Ondertussen is de eerstelijnszone BruZEL al me...   \n",
       "1  Ondertussen is de eerstelijnszone BruZEL al me...   \n",
       "2  Ondertussen is de eerstelijnszone BruZEL al me...   \n",
       "3  Ondertussen is de eerstelijnszone BruZEL al me...   \n",
       "4  Ondertussen is de eerstelijnszone BruZEL al me...   \n",
       "\n",
       "                                            question  statistical  \\\n",
       "0  Zoals alle eerstelijnszones kreeg ook BruZEL h...            0   \n",
       "1  2.Kan de minister toelichten op welke manier B...            0   \n",
       "2  3.Kan de minister in het bijzonder toelichten ...            0   \n",
       "3  4.Kan de minister in het bijzonder toelichten ...            0   \n",
       "4  Zoals alle eerstelijnszones kreeg ook BruZEL h...            0   \n",
       "\n",
       "                        theme    file_name  \\\n",
       "0  Brussel en de Vlaamse Rand  1752898.txt   \n",
       "1  Brussel en de Vlaamse Rand  1752898.txt   \n",
       "2  Brussel en de Vlaamse Rand  1752898.txt   \n",
       "3  Brussel en de Vlaamse Rand  1752898.txt   \n",
       "4  Brussel en de Vlaamse Rand  1752906.txt   \n",
       "\n",
       "                                          clean_text  \n",
       "0  Zoals alle eerstelijnszones kreeg ook BruZEL h...  \n",
       "1  Kan de minister toelichten op welke manier Bru...  \n",
       "2  Kan de minister in het bijzonder toelichten op...  \n",
       "3  Kan de minister in het bijzonder toelichten op...  \n",
       "4  Zoals alle eerstelijnszones kreeg ook BruZEL h...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# âœ… 1. Load & Preprocess Data\n",
    "script_dir = os.path.dirname(os.getcwd()) # Ga Ã©Ã©n map omhoog om 'baseline' te verwijderen en ga naar 'Data'\n",
    "project_root = os.path.dirname(script_dir)  # Dit verwijdert 'baseline' van het script_dir\n",
    "data_folder = os.path.join(project_root, \"Data\")\n",
    "\n",
    "# 1. Dataset inladen\n",
    "file_path = os.path.join(data_folder, \"Grote_data_NoDupsLessThemesENnoWords9.xlsx\")\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90b18e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Recompute label encoding AFTER filtering\n",
    "unique_themes = list(df[\"theme\"].unique())\n",
    "theme_to_id = {theme: idx for idx, theme in enumerate(unique_themes)}\n",
    "id_to_theme = {idx: theme for theme, idx in theme_to_id.items()}\n",
    "df[\"theme_id\"] = df[\"theme\"].map(theme_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ed805a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… 5. Split Data into Train & Test\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df[\"clean_text\"].tolist(), df[\"theme_id\"].tolist(), test_size=0.2, random_state=42, stratify=df[\"theme_id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2626eb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after oversampling: Counter({9: 13730, 2: 8024, 13: 6169, 10: 5314, 4: 4156, 6: 3314, 8: 1860, 12: 1832, 1: 1769, 7: 1444, 3: 1444, 16: 1444, 14: 1444, 15: 1444, 5: 1444, 0: 1444, 11: 1444, 17: 1444})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pandas as pd\n",
    "\n",
    "# Create a small DataFrame from train lists\n",
    "train_df = pd.DataFrame({\n",
    "    \"clean_text\": train_texts,\n",
    "    \"theme_id\": train_labels\n",
    "})\n",
    "\n",
    "# Compute class counts and use median as balancing target\n",
    "theme_counts = train_df[\"theme_id\"].value_counts()\n",
    "median_count = theme_counts.median()\n",
    "\n",
    "# Define strategy: only oversample underrepresented classes\n",
    "sampling_strategy = {\n",
    "    theme: int(median_count)\n",
    "    for theme in theme_counts.index\n",
    "    if theme_counts[theme] < median_count\n",
    "}\n",
    "\n",
    "# Apply RandomOverSampler\n",
    "ros = RandomOverSampler(sampling_strategy=sampling_strategy, random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(train_df[[\"clean_text\"]], train_df[\"theme_id\"])\n",
    "\n",
    "# Extract oversampled train lists\n",
    "train_texts_resampled = X_resampled[\"clean_text\"].tolist()\n",
    "train_labels_resampled = y_resampled.tolist()\n",
    "\n",
    "from collections import Counter\n",
    "print(\"Class distribution after oversampling:\", Counter(train_labels_resampled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b392dad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… 7. Load BERT Tokenizer & Define Dataset Class\n",
    "model_name = \"GroNLP/bert-base-dutch-cased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "class ThemeDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx], padding=\"max_length\", truncation=True, max_length=self.max_length, return_tensors=\"pt\"\n",
    "        )\n",
    "        encoding[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "\n",
    "train_dataset = ThemeDataset(train_texts_resampled, train_labels_resampled, tokenizer)\n",
    "test_dataset = ThemeDataset(test_texts, test_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ebcd1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GroNLP/bert-base-dutch-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# âœ… 8. Load BERT Model for Classification\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=df[\"theme_id\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7423c6f4-03c2-42c7-93bd-ca27f376ee2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\corne\\anaconda3\\envs\\thesis-env\\lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      " 20%|â–ˆâ–ˆ        | 7396/36980 [25:39<1:29:23,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2248, 'grad_norm': 2.864995002746582, 'learning_rate': 1.600216333153056e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      " 20%|â–ˆâ–ˆ        | 7396/36980 [26:55<1:29:23,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9986061453819275, 'eval_accuracy': 0.7077816492450639, 'eval_precision': 0.7191308171893837, 'eval_recall': 0.7077816492450639, 'eval_f1': 0.7079851961555991, 'eval_runtime': 76.362, 'eval_samples_per_second': 169.129, 'eval_steps_per_second': 21.149, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 14792/36980 [52:11<1:06:47,  5.54it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6217, 'grad_norm': 29.80032730102539, 'learning_rate': 1.2003785830178476e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 14792/36980 [53:26<1:06:47,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9320114850997925, 'eval_accuracy': 0.7534649632210608, 'eval_precision': 0.7529976615758746, 'eval_recall': 0.7534649632210608, 'eval_f1': 0.7519637400301361, 'eval_runtime': 75.3369, 'eval_samples_per_second': 171.43, 'eval_steps_per_second': 21.437, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22188/36980 [1:19:44<54:03,  4.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3646, 'grad_norm': 96.64212799072266, 'learning_rate': 8.004867495943754e-06, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22188/36980 [1:21:39<54:03,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.084497094154358, 'eval_accuracy': 0.7669376693766937, 'eval_precision': 0.7674788449588794, 'eval_recall': 0.7669376693766937, 'eval_f1': 0.7658669997098666, 'eval_runtime': 114.6261, 'eval_samples_per_second': 112.671, 'eval_steps_per_second': 14.089, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29584/36980 [1:47:49<22:42,  5.43it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2126, 'grad_norm': 114.7227783203125, 'learning_rate': 4.0070308274743105e-06, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29584/36980 [1:49:06<22:42,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2898962497711182, 'eval_accuracy': 0.7780100658149439, 'eval_precision': 0.7781059003116977, 'eval_recall': 0.7780100658149439, 'eval_f1': 0.7770866213747172, 'eval_runtime': 76.9692, 'eval_samples_per_second': 167.794, 'eval_steps_per_second': 20.982, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36980/36980 [2:15:32<00:00,  4.80it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1206, 'grad_norm': 0.04459055885672569, 'learning_rate': 8.112493239588969e-09, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36980/36980 [2:17:21<00:00,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4250351190567017, 'eval_accuracy': 0.7824235385210995, 'eval_precision': 0.7819829020044837, 'eval_recall': 0.7824235385210995, 'eval_f1': 0.7814077529642066, 'eval_runtime': 108.367, 'eval_samples_per_second': 119.178, 'eval_steps_per_second': 14.903, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36980/36980 [2:17:25<00:00,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 8245.8148, 'train_samples_per_second': 35.875, 'train_steps_per_second': 4.485, 'train_loss': 0.5088666652846555, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=36980, training_loss=0.5088666652846555, metrics={'train_runtime': 8245.8148, 'train_samples_per_second': 35.875, 'train_steps_per_second': 4.485, 'total_flos': 7.784469376782336e+16, 'train_loss': 0.5088666652846555, 'epoch': 5.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# âœ… 9. Define Training Arguments (With Early Stopping)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,                 # ðŸ‘ˆ Keep only the last checkpoint\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,  \n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_strategy=\"epoch\",  # ðŸ”¥ Log only once per epoch\n",
    "    fp16=True,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True\n",
    ")\n",
    "\n",
    "# âœ… 10. Define Metrics for Evaluation\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\", zero_division=1)\n",
    "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "# âœ… 11. Train Model with Early Stopping\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]  # Stop if no improvement for 2 epochs\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c9cbf7",
   "metadata": {},
   "source": [
    "SAVE MODEL TO KUL DRIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b892a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1615/1615 [01:13<00:00, 21.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything saved in: C:/Users/corne/OneDrive - KU Leuven/Thesis/Working Code/SAVED-Models/GroNLP\\Run_2025-04-11_18-10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "# === Create timestamped save path in OneDrive ===\n",
    "run_id = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "base_path = \"C:/Users/corne/OneDrive - KU Leuven/Thesis/Working Code/SAVED-Models/GroNLP\"\n",
    "save_path = os.path.join(base_path, f\"Run_{run_id}\")\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# === Save model using Trainer ===\n",
    "trainer.save_model(save_path)\n",
    "\n",
    "# === Get predictions ===\n",
    "preds_output = trainer.predict(test_dataset)\n",
    "logits = preds_output.predictions\n",
    "predictions = np.argmax(logits, axis=1)\n",
    "\n",
    "# === Save predictions to CSV ===\n",
    "output_df = pd.DataFrame({\n",
    "    \"text\": test_texts,  # make sure test_texts is defined\n",
    "    \"true_label\": test_labels,  # make sure test_labels is defined\n",
    "    \"predicted_label\": predictions,\n",
    "    \"logits\": logits.tolist()\n",
    "})\n",
    "\n",
    "csv_path = os.path.join(save_path, \"test_predictions.csv\")\n",
    "output_df.to_csv(csv_path, index=False)\n",
    "\n",
    "# === Optional: Save a description file ===\n",
    "description = \"\"\"\n",
    "Model: GroNLP BERT-based Dutch Cased\n",
    "Training Details:\n",
    "geen context meegegeven in zowel train als test\n",
    "5 epochs \n",
    "\n",
    "data set : Grote_data_NoDupsLessThemesENnoWords9\n",
    "\"\"\"\n",
    "\n",
    "desc_path = os.path.join(save_path, \"model_description.txt\")\n",
    "with open(desc_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(description)\n",
    "\n",
    "# === Save label mappings ===\n",
    "mappings_path = os.path.join(save_path, \"label_mappings.json\")\n",
    "with open(mappings_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\n",
    "        \"theme_to_id\": theme_to_id,\n",
    "        \"id_to_theme\": {str(k): v for k, v in id_to_theme.items()},  # keys must be str for JSON\n",
    "        \"unique_themes\": unique_themes  # Save the unique themes list\n",
    "\n",
    "    }, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "print(f\"Everything saved in: {save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
