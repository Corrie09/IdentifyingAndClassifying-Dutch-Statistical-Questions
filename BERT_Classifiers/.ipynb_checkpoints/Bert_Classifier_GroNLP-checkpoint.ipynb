{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02f802ec-808c-4c4e-b6da-7d0e38ab4de0",
   "metadata": {},
   "source": [
    "**Bert model op basis van Bert van Universiteit van Groningen. Context handling moet nog aangepast worden. Oversampling a.d.h.v de mediaan. dynamisch treshhold zoeken voor unknown.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24278f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import torch.nn.functional as F\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036522e4-854d-4d1b-91f0-a3a1b93faff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce9fa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 1. Load & Preprocess Data\n",
    "script_dir = os.getcwd() # Ga één map omhoog om 'baseline' te verwijderen en ga naar 'Data'\n",
    "project_root = os.path.dirname(script_dir)  # Dit verwijdert 'baseline' van het script_dir\n",
    "data_folder = os.path.join(project_root, \"Data\")\n",
    "\n",
    "# 1. Dataset inladen\n",
    "file_path = os.path.join(data_folder, \"Grote_data.xlsx\")\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b18e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "if \"TXT_file_name\" in df.columns:\n",
    "    df = df.drop(columns=[\"TXT_file_name\"])\n",
    "\n",
    "# Handle missing values\n",
    "df = df.dropna(subset=[\"question\"])\n",
    "df[\"context\"].fillna(\"\", inplace=True)\n",
    "\n",
    "# ✅ 2. Define Dutch Stopwords & Cleaning Function\n",
    "dutch_stopwords = {\"de\", \"het\", \"een\", \"en\", \"van\", \"ik\", \"te\", \"dat\", \"die\", \"in\", \"je\", \"is\",\n",
    "                   \"niet\", \"op\", \"aan\", \"met\", \"als\", \"voor\", \"zijn\", \"was\", \"heeft\", \"heb\",\n",
    "                   \"om\", \"bij\", \"of\", \"geen\", \"dan\", \"toch\", \"maar\", \"wel\", \"meer\", \"doen\",\n",
    "                   \"ook\", \"kan\", \"mijn\", \"zo\", \"dus\", \"zou\", \"kunnen\"}\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    text = re.sub(r'\\b[a-z]\\)\\s+', ' ', text)  # Remove enumerations\n",
    "    text = re.sub(r'\\b\\d+\\.\\b', '', text)  # Remove numbered lists\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove special characters\n",
    "    text = \" \".join([word for word in text.split() if word not in dutch_stopwords])\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# ✅ 3. Merge Context + Question & Apply Cleaning\n",
    "df[\"clean_text\"] = (df[\"context\"] + \" \" + df[\"question\"]).apply(clean_text)\n",
    "\n",
    "# ✅ 4. Encode Theme Labels as Numbers\n",
    "unique_themes = list(df[\"theme\"].unique())\n",
    "theme_to_id = {theme: idx for idx, theme in enumerate(unique_themes)}\n",
    "id_to_theme = {idx: theme for theme, idx in theme_to_id.items()}  # ✅ Ensure mapping back from ID to theme\n",
    "df[\"theme_id\"] = df[\"theme\"].map(theme_to_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2626eb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 5. Fix Class Imbalance with Oversampling\n",
    "theme_counts = df[\"theme_id\"].value_counts()\n",
    "median_count = theme_counts.median()  # Set balancing threshold\n",
    "\n",
    "# Oversample rare themes\n",
    "sampling_strategy = {theme: int(median_count) for theme in theme_counts.index if theme_counts[theme] < median_count}\n",
    "ros = RandomOverSampler(sampling_strategy=sampling_strategy, random_state=42)\n",
    "\n",
    "X_resampled, y_resampled = ros.fit_resample(df[[\"clean_text\"]], df[\"theme_id\"])\n",
    "df_resampled = pd.DataFrame({\"clean_text\": X_resampled[\"clean_text\"], \"theme_id\": y_resampled})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b392dad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 6. Split Data into Train & Test\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df_resampled[\"clean_text\"].tolist(), df_resampled[\"theme_id\"].tolist(), test_size=0.2, random_state=42, stratify=df_resampled[\"theme_id\"]\n",
    ")\n",
    "\n",
    "# ✅ 7. Load BERT Tokenizer & Define Dataset Class\n",
    "model_name = \"GroNLP/bert-base-dutch-cased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "class ThemeDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx], padding=\"max_length\", truncation=True, max_length=self.max_length, return_tensors=\"pt\"\n",
    "        )\n",
    "        encoding[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "\n",
    "train_dataset = ThemeDataset(train_texts, train_labels, tokenizer)\n",
    "test_dataset = ThemeDataset(test_texts, test_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebcd1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 8. Load BERT Model for Classification\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(unique_themes),output_attentions=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7423c6f4-03c2-42c7-93bd-ca27f376ee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 9. Define Training Arguments (With Early Stopping)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=8,  # Increased epochs\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_strategy=\"epoch\",  # 🔥 Log only once per epoch\n",
    "    fp16=True,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "# ✅ 10. Define Metrics for Evaluation\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\", zero_division=1)\n",
    "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "# ✅ 11. Train Model with Early Stopping\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]  # Stop if no improvement for 2 epochs\n",
    ")\n",
    "\n",
    "model.config.output_attentions = False  # Turn off attention storage while training\n",
    "trainer.train()\n",
    "model.config.output_attentions = True  # Re-enable after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e68926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 13. Make Predictions (With Dynamic Confidence Threshold & Short Question Handling)\n",
    "predictions = trainer.predict(test_dataset)\n",
    "probabilities = F.softmax(torch.tensor(predictions.predictions), dim=1)\n",
    "\n",
    "# ✅ Dynamically Adjust the Confidence Threshold (1st Percentile)\n",
    "confidence_values = torch.max(probabilities, dim=1)[0].tolist()\n",
    "dynamic_threshold = np.percentile(confidence_values, 1)  # ✅ Set threshold at the 5th percentile\n",
    "print(f\"Dynamic Threshold: {dynamic_threshold}\")  # ✅ Print the new threshold\n",
    "\n",
    "# ✅ Predict Themes with \"Unknown\" for Unclear Questions\n",
    "predicted_labels = []\n",
    "for i in range(len(probabilities)):\n",
    "    max_prob = torch.max(probabilities[i]).item()\n",
    "    pred_label = torch.argmax(probabilities[i]).item()\n",
    "    question_text = test_texts[i]\n",
    "\n",
    "    # ✅ If question is too short and lacks context, assign \"Unknown\"\n",
    "    if len(question_text.split()) < 5:\n",
    "        predicted_labels.append(\"Unknown\")\n",
    "    elif max_prob < dynamic_threshold:\n",
    "        predicted_labels.append(\"Unknown\")  # ✅ Filter out low-confidence predictions\n",
    "    else:\n",
    "        predicted_labels.append(id_to_theme[pred_label])  # ✅ Assign label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1462d071",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Visualize the confusion matrix\n",
    "'''\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(labels, predicted_labels)\n",
    "\n",
    "# Visualize it\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=list(id_to_theme.values()), yticklabels=list(id_to_theme.values()))\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023fc296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 14. Save Predictions & CLS Embeddings to Excel\n",
    "output_df = pd.DataFrame({\n",
    "    \"Text\": test_texts,\n",
    "    \"True_Theme\": [id_to_theme[label] for label in test_labels],\n",
    "    \"Predicted_Theme\": predicted_labels\n",
    "})\n",
    "\n",
    "\n",
    "output_df.to_excel(\"BertGroNLP-theme_classification.xlsx\", index=False)\n",
    "print(\"✅ Model Training Completed! Predictions saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3a9947-7d3f-4a26-bd4e-87f4b0659dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 15. Visualize Distribution of Predicted Themes\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# ✅ Replace this with your actual predictions DataFrame\n",
    "# Example: If your predictions are stored in a variable `predicted_labels`\n",
    "# Convert it into a DataFrame for visualization\n",
    "df = pd.DataFrame({\"Predicted_Theme\": predicted_labels})\n",
    "\n",
    "# ✅ Count occurrences of each predicted theme\n",
    "label_counts = df[\"Predicted_Theme\"].value_counts()\n",
    "\n",
    "# ✅ Create the bar plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=label_counts.index, y=label_counts.values)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"Predicted Theme\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of Assigned Labels in Model Predictions\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0b2ed8",
   "metadata": {},
   "source": [
    "TO GET ATTENTION SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83e3e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if GPU is available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b451f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention_and_prediction(clean_text):\n",
    "    \"\"\"Extracts attention scores and model prediction for a given question.\"\"\"\n",
    "    model.config.output_attentions = True  # Ensure attention is enabled\n",
    "\n",
    "    # Tokenize input\n",
    "    tokenizer_inputs = tokenizer(clean_text, return_tensors=\"pt\")  \n",
    "    tokenizer_inputs = {key: val.to(device) for key, val in tokenizer_inputs.items()}  # Move to GPU if available\n",
    "\n",
    "    # Forward pass to get attention scores and logits\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokenizer_inputs)\n",
    "\n",
    "    attentions = outputs.attentions  # Extract attention scores\n",
    "    logits = outputs.logits  # Model prediction scores\n",
    "\n",
    "    predicted_class_id = logits.argmax(dim=1).item()  # Get predicted class ID\n",
    "    predicted_class_name = id_to_theme.get(predicted_class_id, \"Unknown\")  # Convert ID to actual class name\n",
    "\n",
    "    return attentions, predicted_class_id, predicted_class_name\n",
    "\n",
    "\n",
    "test_question = \"Hoeveel subsidies zijn toegekend aan bedrijven?\"\n",
    "attention_scores, predicted_class_id, predicted_class_name = get_attention_and_prediction(test_question)\n",
    "\n",
    "print(f\"✅ Model predicted class: {predicted_class_name} (ID: {predicted_class_id})\")\n",
    "print(f\"🔍 Total Attention Layers Extracted: {len(attention_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7de532c-4264-4ad0-9939-14b471ee539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_attention_with_class(question):\n",
    "    \"\"\"Visualizes attention scores and shows the predicted class.\"\"\"\n",
    "    attentions, predicted_class_id, predicted_class_name = get_attention_and_prediction(question)\n",
    "    \n",
    "    num_layers = len(attentions)\n",
    "    layer = num_layers - 1  # Last layer\n",
    "    head = 0  # Choose the first attention head\n",
    "\n",
    "    attention_matrix = attentions[layer][0, head].cpu().numpy()\n",
    "    tokens = tokenizer.tokenize(question)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(attention_matrix, cmap=\"viridis\", aspect=\"auto\")\n",
    "    plt.xticks(range(len(tokens)), tokens, rotation=90)\n",
    "    plt.yticks(range(len(tokens)), tokens)\n",
    "    plt.colorbar(label=\"Attention Score\")\n",
    "    plt.title(f\"Predicted Class: {predicted_class_name} | Attention Heatmap (Layer {layer+1}, Head {head+1})\")\n",
    "    plt.show()\n",
    "\n",
    "correctly_classified_questions = []\n",
    "\n",
    "for _, row in df.sample(100, random_state=42).iterrows():  # Test 100 random samples\n",
    "    question = row[\"clean_text\"]\n",
    "    true_class = row[\"theme\"]  # The actual correct theme\n",
    "\n",
    "    _, predicted_class_id, predicted_class_name = get_attention_and_prediction(question)\n",
    "\n",
    "    if predicted_class_name == true_class:  # ✅ Now we check for correct predictions\n",
    "        correctly_classified_questions.append((question, true_class, predicted_class_name))\n",
    "\n",
    "# Print first few correctly classified questions\n",
    "print(\"✅ Correctly Classified Questions:\")\n",
    "for q, actual, predicted in correctly_classified_questions[:5]:\n",
    "    print(f\"🔍 Question: {q}\")\n",
    "    print(f\"✅ Actual Class: {actual}\")\n",
    "    print(f\"✅ Predicted Class: {predicted}\\n\")\n",
    "\n",
    "# ✅ If there are correct predictions, visualize one\n",
    "if correctly_classified_questions:\n",
    "    sample_correct = correctly_classified_questions[0]  # Pick first correct prediction\n",
    "    question, actual_class, predicted_class = sample_correct\n",
    "\n",
    "    print(f\"✅ Correctly Classified Example:\")\n",
    "    print(f\"🔍 Question: {question}\")\n",
    "    print(f\"✅ Actual Class: {actual_class}\")\n",
    "    print(f\"✅ Predicted Class: {predicted_class}\")\n",
    "\n",
    "    # Visualize attention for correctly classified question\n",
    "    visualize_attention_with_class(question)\n",
    "else:\n",
    "    print(\"❌ No correctly classified questions found in the sample!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
