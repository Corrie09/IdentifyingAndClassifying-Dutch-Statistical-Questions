{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46607111",
   "metadata": {},
   "source": [
    "ALLEEN Basic Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c879bdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import torch.nn.functional as F\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee381d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 1. Load & Preprocess Data\n",
    "script_dir = os.getcwd() # Ga één map omhoog om 'baseline' te verwijderen en ga naar 'Data'\n",
    "project_root = os.path.dirname(script_dir)  # Dit verwijdert 'baseline' van het script_dir\n",
    "data_folder = os.path.join(project_root, \"Data\")\n",
    "\n",
    "\n",
    "# 1. Dataset inladen\n",
    "file_path = os.path.join(data_folder, \"Grote_data_cleaned.xlsx\")\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93dfd00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows Before filtering: 102015\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of rows Before filtering: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "859b4071",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_27340\\1056078359.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"context\"].fillna(\"\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "if \"TXT_file_name\" in df.columns:\n",
    "    df = df.drop(columns=[\"TXT_file_name\"])\n",
    "\n",
    "# Handle missing values\n",
    "df = df.dropna(subset=[\"question\"])\n",
    "df[\"context\"].fillna(\"\", inplace=True)\n",
    "\n",
    "# Clean text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\n', ' ', text)  # Replace newlines with spaces\n",
    "    text = re.sub(r'\\b[a-z]\\)\\s*', ' ', text)  # Remove patterns like 'a)', 'b)', etc., with optional spaces\n",
    "    text = re.sub(r'\\b\\d+\\.\\b', '', text)  # Remove patterns like '1.', '2.', etc.\n",
    "    text = re.sub(r'\\b\\d+\\)\\b', '', text)  # Remove patterns like '1)', '2)', etc.\n",
    "    text = re.sub(r'\\b[i]+[.)]\\b', '', text, flags=re.IGNORECASE)  # Remove patterns like 'i.', 'ii.', 'i)', etc.\n",
    "    text = re.sub(r'\\b\\d+[.)]\\s*', '', text) # Remove numeric list markers like 1., 2. or 1) 2)\n",
    "    text = re.sub(r'\\b[ivxlcdm]+\\s*[.)]\\s*', '', text, flags=re.IGNORECASE)# Remove roman numerals like i. ii. iii. or i) ii) iii)\n",
    "    text = re.sub(r'•', '', text)  # Remove bullet symbol\n",
    "    text = re.sub(r'\\[\\d+\\]', '', text)  # Remove patterns like '[1]', '[2]', etc.\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces and trim\n",
    "    return text\n",
    "\n",
    "# df[\"clean_text\"] = (df[\"context\"] + \" \" + df[\"question\"]).apply(clean_text)\n",
    "df[\"clean_text\"] = (df[\"question\"]).apply(clean_text) \n",
    "\n",
    "# ✅ Now: drop rare themes using original theme names\n",
    "theme_counts = df[\"theme\"].value_counts()\n",
    "valid_themes = theme_counts[theme_counts >= 2].index\n",
    "df = df[df[\"theme\"].isin(valid_themes)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92059c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after filtering: 102013\n"
     ]
    }
   ],
   "source": [
    "#amount of rows \n",
    "print(f\"Number of rows after filtering: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7b18ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(data_folder, \"Grote_data_cleaned.xlsx\")\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "#Totale data set gewoon gepreprocesseerd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67523333",
   "metadata": {},
   "source": [
    "removes rows where the same clean_text appears with multiple different theme values + Themes worden samengezet naar minder themas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "327fcb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'clean_text' and count unique themes\n",
    "duplicates_with_diff_themes = df.groupby(\"clean_text\")[\"theme\"].nunique().reset_index()\n",
    "\n",
    "# Filter rows where the number of unique themes is greater than 1\n",
    "duplicates_with_diff_themes = duplicates_with_diff_themes[duplicates_with_diff_themes[\"theme\"] > 1]\n",
    "\n",
    "# Merge back with the original dataframe to get all rows with these 'clean_text'\n",
    "filtered_df = df[df[\"clean_text\"].isin(duplicates_with_diff_themes[\"clean_text\"])]\n",
    "# Exclude rows with these 'clean_text' from the original dataframe\n",
    "df = df[~df[\"clean_text\"].isin(duplicates_with_diff_themes[\"clean_text\"])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75ccb291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after filtering: 92503\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of rows after filtering: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f11489b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique themes: 38\n"
     ]
    }
   ],
   "source": [
    "#geeft aantal themas dat er in totaal zijn\n",
    "print(f\"Number of unique themes: {len(df['theme'].unique())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5a3fea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thema-cluster mapping\n",
    "theme_merge_map = {\n",
    "    # Bestuur en Beleid\n",
    "    \"Lokale overheden en Binnenlands bestuur\": \"Bestuur en Beleid\",\n",
    "    \"Vlaamse administratie\": \"Bestuur en Beleid\",\n",
    "    \"Staatshervorming en Verhoudingen binnen de Belgische federale staat\": \"Bestuur en Beleid\",\n",
    "    \"Vlaamse Regering\": \"Bestuur en Beleid\",\n",
    "    \"Vlaams Parlement\": \"Bestuur en Beleid\",\n",
    "\n",
    "    # Mobiliteit en Infrastructuur\n",
    "    \"Mobiliteit en Verkeer\": \"Mobiliteit en Infrastructuur\",\n",
    "    \"Openbare werken\": \"Mobiliteit en Infrastructuur\",\n",
    "    \"Ruimtelijke ordening\": \"Mobiliteit en Infrastructuur\",\n",
    "\n",
    "    # Economie en Arbeid\n",
    "    \"Werk\": \"Economie en Arbeid\",\n",
    "    \"Economie\": \"Economie en Arbeid\",\n",
    "    \"Sociale economie\": \"Economie en Arbeid\",\n",
    "    \"Internationaal ondernemen\": \"Economie en Arbeid\",\n",
    "\n",
    "    # Welzijn en Gezondheid\n",
    "    \"Welzijn en Gezin\": \"Welzijn en Gezondheid\",\n",
    "    \"Gezondheid\": \"Welzijn en Gezondheid\",\n",
    "    \"Armoedebeleid\": \"Welzijn en Gezondheid\",\n",
    "\n",
    "    # Cultuur en Communicatie\n",
    "    \"Cultuur\": \"Cultuur en Communicatie\",\n",
    "    \"Media\": \"Cultuur en Communicatie\",\n",
    "    \"Taalgebruik\": \"Cultuur en Communicatie\",\n",
    "\n",
    "    # Onderwijs en Samenleving\n",
    "    \"Onderwijs en Vorming\": \"Onderwijs en Samenleving\",\n",
    "    \"Gelijke kansen\": \"Onderwijs en Samenleving\",\n",
    "    \"Jeugdbeleid\": \"Onderwijs en Samenleving\",\n",
    "    \"Integratie en Inburgering\": \"Onderwijs en Samenleving\",\n",
    "\n",
    "    # Milieu en Landbouw\n",
    "    \"Natuur en Milieu\": \"Milieu en Landbouw\",\n",
    "    \"Landbouw\": \"Milieu en Landbouw\",\n",
    "    \"Dierenwelzijn\": \"Milieu en Landbouw\",\n",
    "\n",
    "    # Internationaal Beleid\n",
    "    \"Buitenlands beleid\": \"Internationaal Beleid\",\n",
    "    \"Europese instellingen\": \"Internationaal Beleid\",\n",
    "    \"Ontwikkelingssamenwerking\": \"Internationaal Beleid\",\n",
    "    \"Oekraïnecrisis\": \"Internationaal Beleid\",\n",
    "\n",
    "    # Overige (apart laten tenzij weinig samples)\n",
    "    \"Financiën\": \"Financiën\",\n",
    "    \"Begroting\": \"Begroting\",\n",
    "    \"Wetenschap en Innovatie\": \"Wetenschap en Innovatie\",\n",
    "    \"Toerisme\": \"Toerisme\",\n",
    "    \"Justitie en Handhaving\": \"Justitie en Handhaving\",\n",
    "    \"Brussel en de Vlaamse Rand\": \"Brussel en de Vlaamse Rand\",\n",
    "    \"Sport\": \"Sport\",\n",
    "    \"Onroerend erfgoed\": \"Onroerend erfgoed\",\n",
    "    \"Energie\": \"Energie\",\n",
    "    \"Wonen\": \"Wonen\",\n",
    "}\n",
    "# Nieuwe kolom aanmaken met samengevoegde thema's\n",
    "df[\"theme\"] = df[\"theme\"].map(theme_merge_map).fillna(\"Onbekend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "214e34b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique themes: 18\n",
      "Unique themes after mapping:\n",
      "['Brussel en de Vlaamse Rand' 'Energie' 'Milieu en Landbouw' 'Toerisme'\n",
      " 'Economie en Arbeid' 'Sport' 'Bestuur en Beleid' 'Justitie en Handhaving'\n",
      " 'Cultuur en Communicatie' 'Mobiliteit en Infrastructuur'\n",
      " 'Welzijn en Gezondheid' 'Begroting' 'Wonen' 'Onderwijs en Samenleving'\n",
      " 'Internationaal Beleid' 'Onroerend erfgoed' 'Financiën'\n",
      " 'Wetenschap en Innovatie']\n"
     ]
    }
   ],
   "source": [
    "#geeft aantal themas dat er in totaal zijn\n",
    "print(f\"Number of unique themes: {len(df['theme'].unique())}\")\n",
    "# Print the unique themes\n",
    "print(\"Unique themes after mapping:\")\n",
    "print(df[\"theme\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714c188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(data_folder, \"Grote_data_NoDupsLessThemes.xlsx\")\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "#Removes rows where the same clean_text appears with multiple different theme values + Themes worden samengezet naar minder themas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806b9544",
   "metadata": {},
   "source": [
    "Remove rows with sentences less than 9 words (and zin: Kan de minister een overzicht geven)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06893584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where the 'question' column has 5 or fewer words\n",
    "df = df[df['clean_text'].apply(lambda x: len(str(x).split()) > 9)]\n",
    "\n",
    "# Remove rows where the 'question' column contains the specific phrase (with flexible matching)\n",
    "df = df[~df['clean_text'].str.contains(r'\\bKan de minister een overzicht geven\\b', flags=re.IGNORECASE, na=False)]\n",
    "\n",
    "# Remove rows where 'clean_text' contains \"https:\"\n",
    "df = df[~df['clean_text'].str.contains(r'https:', flags=re.IGNORECASE, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bb91ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after filtering: 64572\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of rows after filtering: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a5787b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(data_folder, \"Grote_data_NoDupsLessThemesENnoWords9.xlsx\")\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "#Remove rows with sentences less than 9 words (and zin: Kan de minister een overzicht geven)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa43ed64",
   "metadata": {},
   "source": [
    "KLEINERE DATASET MAKEN van de 3 vorige (voor sneller testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a224948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 1. Load & Preprocess Data\n",
    "script_dir = os.getcwd()  # Ga één map omhoog om 'baseline' te verwijderen en ga naar 'Data'\n",
    "project_root = os.path.dirname(script_dir)  # Dit verwijdert 'baseline' van het script_dir\n",
    "data_folder = os.path.join(project_root, \"Data\")\n",
    "\n",
    "# 1. Dataset inladen\n",
    "file_path = os.path.join(data_folder, \"Grote_data_cleaned.xlsx\")\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Neem willekeurig 30.000 rijen\n",
    "sample_df = df.sample(n=30000, random_state=42)\n",
    "\n",
    "# Bepaal pad naar de bestaande 'Klein' map\n",
    "originele_map = os.path.dirname(file_path)  # << hier was de fout\n",
    "klein_map = os.path.join(originele_map, \"Klein\")\n",
    "\n",
    "# Pad naar output-bestand\n",
    "output_pad = os.path.join(klein_map, \"Grote_data_cleaned_30000.xlsx\")\n",
    "\n",
    "# Sla het sample op\n",
    "sample_df.to_excel(output_pad, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d151db10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 1. Load & Preprocess Data\n",
    "script_dir = os.getcwd()  # Ga één map omhoog om 'baseline' te verwijderen en ga naar 'Data'\n",
    "project_root = os.path.dirname(script_dir)  # Dit verwijdert 'baseline' van het script_dir\n",
    "data_folder = os.path.join(project_root, \"Data\")\n",
    "\n",
    "# 1. Dataset inladen\n",
    "file_path = os.path.join(data_folder, \"Grote_data_NoDupsLessThemes.xlsx\")\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Neem willekeurig 30.000 rijen\n",
    "sample_df = df.sample(n=30000, random_state=42)\n",
    "\n",
    "# Bepaal pad naar de bestaande 'Klein' map\n",
    "originele_map = os.path.dirname(file_path)  # << hier was de fout\n",
    "klein_map = os.path.join(originele_map, \"Klein\")\n",
    "\n",
    "# Pad naar output-bestand\n",
    "output_pad = os.path.join(klein_map, \"Grote_data_NoDupsLessThemes_30000.xlsx\")\n",
    "\n",
    "# Sla het sample op\n",
    "sample_df.to_excel(output_pad, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4359e457",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ✅ 1. Load & Preprocess Data\n",
    "script_dir = os.getcwd()  # Ga één map omhoog om 'baseline' te verwijderen en ga naar 'Data'\n",
    "project_root = os.path.dirname(script_dir)  # Dit verwijdert 'baseline' van het script_dir\n",
    "data_folder = os.path.join(project_root, \"Data\")\n",
    "\n",
    "# 1. Dataset inladen\n",
    "file_path = os.path.join(data_folder, \"Grote_data_NoDupsLessThemesENnoWords9.xlsx\")\n",
    "\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Neem willekeurig 30.000 rijen\n",
    "sample_df = df.sample(n=30000, random_state=42)\n",
    "\n",
    "# Bepaal pad naar de bestaande 'Klein' map\n",
    "originele_map = os.path.dirname(file_path)  # << hier was de fout\n",
    "klein_map = os.path.join(originele_map, \"Klein\")\n",
    "\n",
    "# Pad naar output-bestand\n",
    "output_pad = os.path.join(klein_map, \"Grote_data_NoDupsLessThemesENnoWords9_30000.xlsx\")\n",
    "\n",
    "# Sla het sample op\n",
    "sample_df.to_excel(output_pad, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
