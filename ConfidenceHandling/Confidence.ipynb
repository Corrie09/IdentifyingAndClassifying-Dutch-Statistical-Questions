{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Andere manier om te kijken naar evaluation, i.p.v terug te splitten en te predicten, nu opgeslagen predicition gebruiken**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import json  # Needed for loading the mappings\n",
    "\n",
    "# === Define path to the saved run ===\n",
    "save_path = r\"C:\\Users\\corne\\OneDrive - KU Leuven\\Thesis\\Working Code\\SAVED-Models\\GroNLP\\Run_2025-04-10_15-17\"\n",
    "\n",
    "# ‚úÖ Load the saved test predictions \n",
    "df = pd.read_csv(os.path.join(save_path, \"test_predictions.csv\"))\n",
    "\n",
    "# ‚úÖ Recreate logits tensor from the CSV\n",
    "logits = torch.tensor(df[\"logits\"].apply(eval).tolist())\n",
    "\n",
    "# ‚úÖ Apply softmax to get prediction probabilities\n",
    "probabilities = F.softmax(logits, dim=1)\n",
    "\n",
    "# ‚úÖ Extract raw values\n",
    "texts = df[\"text\"].tolist()\n",
    "true_labels_ids = df[\"true_label\"].tolist()\n",
    "predicted_label_ids = df[\"predicted_label\"].tolist()\n",
    "\n",
    "# ‚úÖ Convert label IDs to themes using the mappings\n",
    "with open(os.path.join(save_path, \"label_mappings.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    mappings = json.load(f)\n",
    "\n",
    "theme_to_id = mappings[\"theme_to_id\"]\n",
    "id_to_theme = {int(k): v for k, v in mappings[\"id_to_theme\"].items()}  # convert keys back to int\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unknowns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Confidence: 1.00\n",
      "‚ùå True: Lokale overheden en Binnenlands bestuur | Predicted: Mobiliteit en Verkeer\n",
      "üí¨ Text: ‚Ä¢Is er een snelheidsproblematiek in combinatie met ongevallen aanwezig?\n",
      "--------------------------------------------------\n",
      "üß† Confidence: 1.00\n",
      "‚ùå True: Wonen | Predicted: Mobiliteit en Verkeer\n",
      "üí¨ Text: Welke fasering in de tijd is er voorzien?\n",
      "--------------------------------------------------\n",
      "üß† Confidence: 1.00\n",
      "‚ùå True: Ruimtelijke ordening | Predicted: Mobiliteit en Verkeer\n",
      "üí¨ Text: Welke timing is vooropgesteld voor de goedkeuring voorontwerp en de start van de werken?\n",
      "--------------------------------------------------\n",
      "üß† Confidence: 1.00\n",
      "‚ùå True: Onroerend erfgoed | Predicted: Mobiliteit en Verkeer\n",
      "üí¨ Text: Welke werken staan nog op de planning?\n",
      "--------------------------------------------------\n",
      "üß† Confidence: 1.00\n",
      "‚ùå True: Openbare werken | Predicted: Mobiliteit en Verkeer\n",
      "üí¨ Text: Kan de minister van Mobiliteit meedelen of het artikel 10 van het BAM-decreet volgens haar en haar collega‚Äôs in de Vlaamse Regering in deze optiek nog langer in zijn huidige vorm behouden kan blijven dan wel, rekening houdende met de hoger beschreven adviezen van de Onderzoekscommissie PFAS-PFOS, bijgestuurd dient te worden?\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Find most confidently wrong predictions\n",
    "probs_np = probabilities.numpy()\n",
    "confidences = probs_np.max(axis=1)\n",
    "\n",
    "errors = []\n",
    "for i in range(len(texts)):\n",
    "    if true_labels_ids[i] != predicted_label_ids[i]:\n",
    "        errors.append((confidences[i], texts[i], id_to_theme[true_labels_ids[i]], id_to_theme[predicted_label_ids[i]]))\n",
    "\n",
    "# Sort by confidence descending\n",
    "errors.sort(reverse=True)\n",
    "\n",
    "# Show top 5\n",
    "for confidence, text, true_theme, predicted_theme in errors[:5]:\n",
    "    print(f\"üß† Confidence: {confidence:.2f}\")\n",
    "    print(f\"‚ùå True: {true_theme} | Predicted: {predicted_theme}\")\n",
    "    print(f\"üí¨ Text: {text}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sorted report saved to: c:\\Users\\corne\\Documents\\thesis-question-classification\\ConfidenceHandling\\prediction_confidence_report.xlsx\n"
     ]
    }
   ],
   "source": [
    "true_labels = [id_to_theme[i] for i in true_labels_ids]\n",
    "predicted_labels = [id_to_theme[i] for i in predicted_label_ids]\n",
    "correct = [true == pred for true, pred in zip(true_labels, predicted_labels)]\n",
    "\n",
    "output_df = pd.DataFrame({\n",
    "    \"text\": texts,\n",
    "    \"true_label\": true_labels,\n",
    "    \"predicted_label\": predicted_labels,\n",
    "    \"is_correct\": correct,\n",
    "    \"confidence\": confidences\n",
    "})\n",
    "\n",
    "# ‚úÖ Sort: incorrect first, then by highest confidence\n",
    "output_df = output_df.sort_values(by=[\"is_correct\", \"confidence\"], ascending=[True, False])\n",
    "\n",
    "# ‚úÖ Optional: add ranking\n",
    "output_df[\"rank\"] = range(1, len(output_df) + 1)\n",
    "\n",
    "# ‚úÖ Save to Excel\n",
    "excel_path = os.path.join(os.getcwd(), \"prediction_confidence_report.xlsx\")\n",
    "output_df.to_excel(excel_path, index=False)\n",
    "print(f\"‚úÖ Sorted report saved to: {excel_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
