{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = os.getcwd() # Ga Ã©Ã©n map omhoog om 'baseline' te verwijderen en ga naar 'Data'\n",
    "project_root = os.path.dirname(script_dir)  # Dit verwijdert 'baseline' van het script_dir\n",
    "data_folder = os.path.join(project_root, \"Data\")\n",
    "\n",
    "# 1. Dataset inladen\n",
    "file_path = os.path.join(data_folder, \"Grote_data.xlsx\")\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             context  \\\n",
      "0  Ambtenaren Vlaamse overheid  -  HoofddoekWat h...   \n",
      "1  Ambtenaren Vlaamse overheid  -  HoofddoekWat h...   \n",
      "2  Ambtenaren Vlaamse overheid  -  HoofddoekWat h...   \n",
      "3  Ambtenaren Vlaamse overheid  -  HoofddoekWat h...   \n",
      "4  Ambtenaren Vlaamse overheid  -  HoofddoekWat h...   \n",
      "\n",
      "                                            question  \\\n",
      "0  Kan de minister voor elke instelling (departem...   \n",
      "1  a) Indien er geen richtlijnen bestaan, hoe wor...   \n",
      "2  b) Is het een ambtenaar die in contact komt me...   \n",
      "3  c) Is het een ambtenaar die niet in contact ko...   \n",
      "4  d) Dringt de minister er bij zijn/haar collega...   \n",
      "\n",
      "                                    context_question  \n",
      "0  Ambtenaren Vlaamse overheid  -  HoofddoekWat h...  \n",
      "1  Ambtenaren Vlaamse overheid  -  HoofddoekWat h...  \n",
      "2  Ambtenaren Vlaamse overheid  -  HoofddoekWat h...  \n",
      "3  Ambtenaren Vlaamse overheid  -  HoofddoekWat h...  \n",
      "4  Ambtenaren Vlaamse overheid  -  HoofddoekWat h...  \n"
     ]
    }
   ],
   "source": [
    "# Create a new column by concatenating 'context' and 'question'\n",
    "df['context_question'] = df['context'] + \" \" + df['question']\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df[['context', 'question', 'context_question']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered rows saved to c:\\Users\\corne\\Documents\\thesis-question-classification\\Data\\filtered_context_question_sorted.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Group by 'context_question' and count unique themes\n",
    "duplicates_with_diff_themes = df.groupby(\"context_question\")[\"theme\"].nunique().reset_index()\n",
    "\n",
    "# Filter rows where the number of unique themes is greater than 1\n",
    "duplicates_with_diff_themes = duplicates_with_diff_themes[duplicates_with_diff_themes[\"theme\"] > 1]\n",
    "\n",
    "# Merge back with the original dataframe to get all rows with these 'context_question'\n",
    "filtered_df = df[df[\"context_question\"].isin(duplicates_with_diff_themes[\"context_question\"])]\n",
    "\n",
    "# Sort the filtered DataFrame by 'context_question' for better readability\n",
    "filtered_df = filtered_df.sort_values(by=[\"context_question\", \"theme\"])\n",
    "\n",
    "# Save the filtered rows to an Excel file\n",
    "output_file_path = os.path.join(data_folder, \"filtered_context_question_sorted.xlsx\")\n",
    "filtered_df.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"Filtered rows saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aantal vragen met verschillende thema's: 320\n",
      "Vragen met verschillende thema's:\n",
      "                                                question  theme\n",
      "301    Acht de minister het gereserveerde budget voor...      2\n",
      "325    Acht de minister het vooropgestelde budget voo...      3\n",
      "388    Als er grote verschillen zijn in het aantal aa...      2\n",
      "418                                           Arbitrair?      2\n",
      "465    Beschikt de minister over de voornaamste reden...      2\n",
      "...                                                  ...    ...\n",
      "19466  f) Wordt na een klantencontact standaard een b...     21\n",
      "19473  g) Hoe wordt bepaald welke aspecten van de die...     21\n",
      "19487      g) Wat is de stand van zaken van het project?      2\n",
      "19506         h) Worden de resultaten gestandaardiseerd?     21\n",
      "19590  vanaf de eerste dag van de publicatie (kenbaar...     10\n",
      "\n",
      "[320 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# Groeperen op \"question\" en tellen hoeveel unieke thema's er zijn per vraag\n",
    "duplicates_with_diff_themes = df.groupby(\"question\")[\"theme\"].nunique().reset_index()\n",
    "\n",
    "# Aantal vragen die meer dan Ã©Ã©n thema hebben\n",
    "num_questions_with_diff_themes = duplicates_with_diff_themes[duplicates_with_diff_themes[\"theme\"] > 1].shape[0]\n",
    "\n",
    "# Print het resultaat\n",
    "print(f\"Aantal vragen met verschillende thema's: {num_questions_with_diff_themes}\")\n",
    "\n",
    "print(\"Vragen met verschillende thema's:\")\n",
    "print(duplicates_with_diff_themes[duplicates_with_diff_themes[\"theme\"] > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missende waarden per kolom:\n",
      "context        9\n",
      "question       0\n",
      "statistical    0\n",
      "theme          0\n",
      "file_name      0\n",
      "dtype: int64\n",
      "\n",
      "Unieke waarden per kolom:\n",
      "context         9967\n",
      "question       19643\n",
      "statistical        2\n",
      "theme             37\n",
      "file_name       3471\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\corne\\anaconda3\\envs\\thesis-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mnunique())\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# ðŸ“Œ 3. Basis statistieken van tekst\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_lengte\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mstr\u001b[39m(x)))  \u001b[38;5;66;03m# Pas 'text' aan naar jouw kolomnaam\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBeschrijving van tekstlengtes:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_lengte\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe())\n",
      "File \u001b[1;32mc:\\Users\\corne\\anaconda3\\envs\\thesis-env\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\corne\\anaconda3\\envs\\thesis-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": [
    "# Missende waarden controleren\n",
    "print(\"\\nMissende waarden per kolom:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Unieke waarden per kolom\n",
    "print(\"\\nUnieke waarden per kolom:\")\n",
    "print(df.nunique())\n",
    "\n",
    "# ðŸ“Œ 3. Basis statistieken van tekst\n",
    "df['text_lengte'] = df['text'].apply(lambda x: len(str(x)))  # Pas 'text' aan naar jouw kolomnaam\n",
    "\n",
    "print(\"\\nBeschrijving van tekstlengtes:\")\n",
    "print(df['text_lengte'].describe())\n",
    "\n",
    "# Visualisatie tekstlengtes\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(df['text_lengte'], bins=50, kde=True)\n",
    "plt.title(\"Verdeling van Tekstlengtes\")\n",
    "plt.xlabel(\"Tekstlengte\")\n",
    "plt.ylabel(\"Frequentie\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zet dit aan als je stopwoorden wilt gebruiken\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# ðŸ“Œ 1. Dataset inladen\n",
    "file_path = \"pad/naar/Grote_data.xlsx\"  # Pas dit aan\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# ðŸ“Œ 2. Data verkennen\n",
    "print(\"Dataset overzicht:\")\n",
    "print(df.info())\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "\n",
    "# ðŸ“Œ 4. Woordanalyse\n",
    "stopwoorden = set(stopwords.words('dutch'))  # Verander naar 'english' of andere taal indien nodig\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(str(text).lower())\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stopwoorden]\n",
    "    return tokens\n",
    "\n",
    "df['tokens'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# Woordfrequenties\n",
    "woorden = [woord for sublist in df['tokens'] for woord in sublist]\n",
    "woord_frequenties = Counter(woorden)\n",
    "\n",
    "print(\"\\nTop 10 meest voorkomende woorden:\")\n",
    "print(woord_frequenties.most_common(10))\n",
    "\n",
    "# Woordcloud genereren\n",
    "wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(\" \".join(woorden))\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# ðŸ“Œ 5. N-gram analyse (bigrammen en trigrammen)\n",
    "vectorizer = CountVectorizer(ngram_range=(2,3), stop_words=list(stopwoorden))\n",
    "X_ngrams = vectorizer.fit_transform(df['text'].dropna())\n",
    "\n",
    "ngram_frequenties = Counter(dict(zip(vectorizer.get_feature_names_out(), X_ngrams.toarray().sum(axis=0))))\n",
    "print(\"\\nTop 10 meest voorkomende bigrammen/trigrammen:\")\n",
    "print(ngram_frequenties.most_common(10))\n",
    "\n",
    "# ðŸ“Œ 6. TF-IDF Vectorisatie\n",
    "tfidf = TfidfVectorizer(stop_words=list(stopwoorden))\n",
    "X_tfidf = tfidf.fit_transform(df['text'].dropna())\n",
    "\n",
    "# ðŸ“Œ 7. Dimensiereductie: PCA & t-SNE\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_tfidf.toarray())\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1])\n",
    "plt.title(\"PCA Visualisatie van de Data\")\n",
    "plt.show()\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_tsne = tsne.fit_transform(X_tfidf.toarray())\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=X_tsne[:,0], y=X_tsne[:,1])\n",
    "plt.title(\"t-SNE Visualisatie van de Data\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
