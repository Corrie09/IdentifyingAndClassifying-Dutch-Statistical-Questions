{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdc7a590-baaf-4bf5-944d-e78e134581f3",
   "metadata": {},
   "source": [
    "**Code die questions haalt uit de txt files en ze in een excel plaatst met een thema en context zinnen. Onze definitie van een statistiche vraag: een vraag waarop een numeriek antwoord, gehaald uit een database, kan gegeven worden. De methodologie van hoe en op basis van welke woorden moet nog verder bekekenen en onderzocht worden. Momenteel plaatsen we bij elke vraag 2 contextzinnen. We gaan nog op zoek naar de ideale hoeveelheid context.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2e66a44-d408-4abc-8bc9-42b69ab66d46",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 195\u001b[0m\n\u001b[0;32m    192\u001b[0m             questions_with_custom_subgrouping \u001b[38;5;241m=\u001b[39m extract_questions_with_custom_subgrouping(content)\n\u001b[0;32m    194\u001b[0m             \u001b[38;5;66;03m# Store extracted questions and their classification\u001b[39;00m\n\u001b[1;32m--> 195\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m context, question \u001b[38;5;129;01min\u001b[39;00m questions_with_custom_subgrouping:\n\u001b[0;32m    196\u001b[0m                 data\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m    197\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: context,\n\u001b[0;32m    198\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: question,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    201\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: file_name  \u001b[38;5;66;03m# Add the file name as a column\u001b[39;00m\n\u001b[0;32m    202\u001b[0m                 })\n\u001b[0;32m    204\u001b[0m \u001b[38;5;66;03m# Convert to DataFrame\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "#aanhef verwijderen zodat die niet mee in vraag of context komt alsook de full caption text in het midden\n",
    "#Identifier vraagwoorden veranderd\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "Script to extract questions from text files while:\n",
    "✔ Skipping metadata (e.g., title, theme, PDF link, sender, recipient, date).\n",
    "✔ Grouping sub-questions **only when they follow a question and start with \"Zo ja\" or \"Graag\".**\n",
    "✔ Keeping all other questions separate.\n",
    "✔ Ensuring that numbered list items (1., 2., etc.) are NOT used as context.\n",
    "✔ Assigning the last two **non-question** sentences as context.\n",
    "✔ Identifying statistical questions.\n",
    "✔ Extracting the theme from the file.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Haal de huidige werkdirectory op (Jupyter gebruikt geen __file__)\n",
    "script_dir = os.getcwd()# Ga één map omhoog om 'Identifier' te verwijderen en ga naar 'Data'\n",
    "project_root = os.path.dirname(script_dir)  # Dit verwijdert 'Identifier'\n",
    "folder_path = os.path.join(project_root, \"Data\", \"ScrapeddocumentsCorneel(22-25)\")\n",
    "excel_path = os.path.join(project_root, \"Data\")\n",
    "\n",
    "\n",
    "# Define Dutch patterns for identifying statistical questions\n",
    "dutch_statistical_patterns = [\n",
    "    r\"\\b(hoeveel|aantal|percentage van|percentage|cijfer over|data over|statistieken van)\\b\",\n",
    "    r\"\\b(trend in|evolutie van|groei van|toename van|afname van|ontwikkeling van)\\b\",\n",
    "    r\"\\b(?:verschaffen|geven|tonen|lijst|overzicht van)?\\s*(de|een)?\\s*(gegevens|statistieken|cijfers)\\b\"\n",
    "]\n",
    "\n",
    "# Function to determine if a question is statistical\n",
    "def is_dutch_statistical(question):\n",
    "    return any(re.search(pattern, question, re.IGNORECASE) for pattern in dutch_statistical_patterns)\n",
    "\n",
    "# Function to remove metadata from the text\n",
    "def remove_metadata(text):\n",
    "    \"\"\"\n",
    "    Removes introductory metadata such as title, theme, PDF link, sender, recipient, date, and headers.\n",
    "    Also removes any line that contains \"MINISTER\" in full uppercase and any fully capitalized lines.\n",
    "    \"\"\"\n",
    "    # Define patterns to detect metadata (title, theme, sender, recipient, etc.)\n",
    "    metadata_patterns = [\n",
    "        r\"(?i)^title:.*\",  # Matches \"title: ...\"\n",
    "        r\"(?i)^thema:.*\",  # Matches \"thema: ...\"\n",
    "        r\"(?i)^pdf link:.*\",  # Matches \"pdf link: ...\"\n",
    "        r\"(?i)^thema link:.*\",  # Matches \"thema link: ...\"\n",
    "        r\"(?i)^SCHRIFTELIJKE VRAAG.*\",  # Matches \"SCHRIFTELIJKE VRAAG ...\"\n",
    "        r\"(?i)^nr\\.\\s*\\d+\\s*$\",  # Matches \"nr. 3 ...\"\n",
    "        r\"(?i)^van\\s+.*\",  # Matches \"van ANKE VAN DERMEERSCH\"\n",
    "        r\"(?i)^datum:.*\",  # Matches \"datum: 23 juli 2024\"\n",
    "        r\"(?i)^aan\\s+.*\",  # Matches \"aan BENJAMIN DALLE\"\n",
    "        r\"(?i)^onderwerp:.*\",  # Matches \"onderwerp: ...\"\n",
    "        r\"(?i)^programma’s.*\",  # Matches \"Programma’s ...\"\n",
    "        r\"(?i)^vraag van.*\",  # Matches \"vraag van ...\"\n",
    "    ]\n",
    "\n",
    "    # Split text into lines\n",
    "    lines = text.split(\"\\n\")\n",
    "\n",
    "    # Function to check if a line is fully uppercase (ignoring numbers/symbols)\n",
    "    def is_fully_uppercase(line):\n",
    "        words = re.findall(r\"[A-Za-zÀ-ÿ]\", line)  # Get only letters (ignoring numbers/punctuation)\n",
    "        return words and all(word.isupper() for word in words)  # Check if all words are uppercase\n",
    "\n",
    "    # Remove lines that match metadata patterns or are fully uppercase\n",
    "    filtered_lines = [line for line in lines if not any(re.search(pattern, line) for pattern in metadata_patterns) and not is_fully_uppercase(line)]\n",
    "\n",
    "    # Return cleaned content (excluding metadata)\n",
    "    return \"\\n\".join(filtered_lines).strip()\n",
    "\n",
    "\n",
    "# Function to extract questions while excluding metadata\n",
    "def extract_questions_with_custom_subgrouping(text):\n",
    "    \"\"\"\n",
    "    Extracts questions from text, grouping only when a question is immediately followed by \n",
    "    \"Zo ja\" or \"Graag\". Ensures other questions remain separate.\n",
    "    Also ensures that numbered list items (1., 2.) are NOT used as context.\n",
    "\n",
    "    Args:\n",
    "    - text (str): The full document text.\n",
    "\n",
    "    Returns:\n",
    "    - List of tuples (context, question)\n",
    "    \"\"\"\n",
    "    # Remove metadata first\n",
    "    text = remove_metadata(text)\n",
    "\n",
    "    import re\n",
    "\n",
    "def smart_sentence_split(text):\n",
    "    abbreviations = [\n",
    "        \"t.o.v.\", \"a.d.h.v.\", \"i.v.m.\", \"m.b.t.\", \"m.a.w.\", \"d.w.z.\",\n",
    "        \"z.o.z.\", \"o.a.\", \"e.d.\", \"e.o.\", \"n.a.v.\", \"v.w.b.\", \"c.q.\",\n",
    "        \"d.d.\", \"m.n.\", \"p.m.\", \"r.i.p.\", \"s.v.p.\", \"t.a.v.\", \"t.k.\",\n",
    "        \"t.z.t.\", \"z.g.a.n.\", \"z.s.m.\", \"z.n.\", \"z.d.\", \"z.m.\",\n",
    "    ]\n",
    "\n",
    "    # Create a mapping: abbreviation -> safe placeholder (e.g., t.o.v. -> __AFKORTING_0__)\n",
    "    abbr_map = {abbr: f\"__AFKORTING_{i}__\" for i, abbr in enumerate(abbreviations)}\n",
    "    for abbr, placeholder in abbr_map.items():\n",
    "        text = text.replace(abbr, placeholder)\n",
    "\n",
    "    # Now split sentences without worrying about abbreviation dots\n",
    "    pattern = r'''\n",
    "        (?<!\\b\\d)              # not after digit (to avoid 1., 2.)\n",
    "        (?<!\\bnr)              # not after \"nr\"\n",
    "        (?<!\\b[i,v,x]{1,5})    # not after roman numerals\n",
    "        (?<=[?.!])             # lookbehind for end punctuation\n",
    "        \\s+                    # whitespace follows\n",
    "    '''\n",
    "    sentences = re.split(pattern, text, flags=re.IGNORECASE | re.VERBOSE)\n",
    "\n",
    "    # Replace placeholders back to abbreviations\n",
    "    restored = []\n",
    "    for sentence in sentences:\n",
    "        for abbr, placeholder in abbr_map.items():\n",
    "            sentence = sentence.replace(placeholder, abbr)\n",
    "        restored.append(sentence)\n",
    "\n",
    "    return restored\n",
    "\n",
    "\n",
    "    # Split text into sentences\n",
    "    sentences = smart_sentence_split(text)\n",
    "\n",
    "\n",
    "    extracted_data = []\n",
    "    prev_non_question_sentences = []  # Tracks last two non-question sentences (excluding numbered list items)\n",
    "    current_question_group = []  # Holds grouped main+sub-questions\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        # Check if the sentence is a question\n",
    "        is_question = re.search(r\"\\?\", sentence)\n",
    "\n",
    "        # Check if it starts with \"Zo ja\" or \"Graag\" (indicating a sub-question)\n",
    "        is_subquestion = re.match(r\"^\\s*(Zo ja|Graag)\\b\", sentence, re.IGNORECASE)\n",
    "\n",
    "        # Check if it's a numbered list item (e.g., \"1.\", \"2.\")\n",
    "        is_numbered_list_item = re.match(r\"^\\s*\\d+\\.\", sentence)\n",
    "\n",
    "        if is_question:\n",
    "            # If we're already grouping a main question and this sentence is \"Zo ja\"/\"Graag\", add it\n",
    "            if current_question_group and is_subquestion:\n",
    "                current_question_group.append(sentence)\n",
    "            else:\n",
    "                # If we already have a grouped question, finalize and store it\n",
    "                if current_question_group:\n",
    "                    context = \" \".join(prev_non_question_sentences[-2:])  # Take last two non-question sentences\n",
    "                    full_question = \" \".join(current_question_group)  # Combine main question + sub-questions\n",
    "                    extracted_data.append((context, full_question))\n",
    "                    current_question_group = []  # Reset the group\n",
    "\n",
    "                current_question_group.append(sentence)  # Start new question group\n",
    "        else:\n",
    "            # If it's a non-question sentence and NOT a numbered list item, add it to the tracking list\n",
    "            # If it's a non-question sentence, not a numbered list item, and does NOT start with \"Graag\"\n",
    "            if (\n",
    "                not is_numbered_list_item and\n",
    "                not re.search(r\"\\?\", sentence) and\n",
    "                not sentence.strip().lower().startswith(\"graag\")\n",
    "            ):\n",
    "                prev_non_question_sentences.append(sentence)\n",
    "                if len(prev_non_question_sentences) > 2:\n",
    "                    prev_non_question_sentences.pop(0)  # Keep only the last two valid context sentences\n",
    "\n",
    "\n",
    "            # If we were collecting a question group and hit a non-question, finalize it\n",
    "            if current_question_group:\n",
    "                context = \" \".join(prev_non_question_sentences[-2:])\n",
    "                full_question = \" \".join(current_question_group)\n",
    "                extracted_data.append((context, full_question))\n",
    "                current_question_group = []  # Reset\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "# Process each file\n",
    "data = []\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            content = file.read()\n",
    "\n",
    "            # Extract the theme (assuming it's always at the start of the file)\n",
    "            theme_match = re.search(r\"thema:\\s*(.+)\", content, re.IGNORECASE)\n",
    "            theme = theme_match.group(1).strip() if theme_match else \"Unknown\"\n",
    "\n",
    "            # Extract questions with updated grouping logic\n",
    "            questions_with_custom_subgrouping = extract_questions_with_custom_subgrouping(content)\n",
    "\n",
    "            # Store extracted questions and their classification\n",
    "            for context, question in questions_with_custom_subgrouping:\n",
    "                data.append({\n",
    "                    \"context\": context,\n",
    "                    \"question\": question,\n",
    "                    \"statistical\": 1 if is_dutch_statistical(question) else 0,\n",
    "                    \"theme\": theme,\n",
    "                    \"file_name\": file_name  # Add the file name as a column\n",
    "                })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to Excel file\n",
    "output_excel_path = os.path.join(excel_path, \"Grote_data_cleaned.xlsx\")\n",
    "# Remove NULL bytes and control characters before saving\n",
    "df = df.applymap(lambda x: ''.join(c for c in str(x) if c.isprintable()) if isinstance(x, str) else x)\n",
    "\n",
    "df.to_excel(output_excel_path, index=False, engine=\"openpyxl\")\n",
    "\n",
    "print(f\"Extraction complete! The file is saved at: {output_excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4b0998-e2c7-41cd-8890-8621dba815fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
